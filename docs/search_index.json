[["index.html", "bluebook BIOSCI738 Preface 0.1 Course Overview 0.2 Key Topics", " bluebook BIOSCI738 Charlotte Jones-Todd Semester 1, 2021, University of Auckland Preface Artwork by @allison_horst 0.1 Course Overview This is a postgraduate course in statistical methods geared towards the needs of students of biology, ecology, and environmental science. Whether heading to research or industry, it is imperative that biology students have the statistical and computational skills to apply and interpret fundamental statistical concepts and analyses to assess and critique their experiments and other data. This course is suited to students with an interest in (bio)statistics who would like to equip themselves with the tools and know-how to be able to correctly prepare experiments, analyse data, interpret their results and draw valid conclusions. The statistical concepts and methods taught in this course will provide students with the tools to make and evaluate scientific discoveries as well as propose and justify decisions based on data. Some basic statistical knowledg is assumed. This course will use the programming language R; R is a free software environment for statistical computing and graphics. Students are strongly encouraged to use R through the freely available IDE (integrated development environment) RStudio. Students will have access to R and RStudio in university computing laboratories, but are also encouraged to download and install R and RStudio on their own devices. 0.2 Key Topics Taught material will be delivered, each week, via 2 hour lectures. Each week there will also be a 1 hour practical workshop focused on the material covered in the lecture. A list of topics and concepts covert in this course is given below. Exploratory Data Analysis and Communication Data wrangling Data visualisation Experimental Design and Statistical Inference Introduction to design and analysis of experiments Comparison procedures: pairwise comparisons of means, one-way ANOVA Multiple comparison procedures (controlling errors in hypothesis testing) Multiple regression with continuous and categorical explanatory variables Mixed models; incorporating fixed and random effects Resampling procedures: randomisation, permutation, and bootstrapping Multivariate Analysis Cluster analysis Unsupervised learning: principal components analysis, dimension reduction Ordination: multidimensional scaling, correspondence analysis Supervised learning: discriminant analysis Networks and graphs "],["r-rstudio-and-git.html", "1 R, RStudio, and git 1.1 Learning objectives 1.2 Intro to R &amp; RStudio 1.3 Getting started 1.4 Reproducible research 1.5 git and GitHub 1.6 Exploratory Data Analysis 1.7 Other resources", " 1 R, RStudio, and git 1.1 Learning objectives Define the difference between R and RStudio Explain what an R function is; describe what an argument to an R function is Explain what an R package is; distinguish between the functions install.packages() and library() Use the appropriate R function to read in a data file Explain the importance of reproducibility in terms of scientific research Use the functionality offered by git and GitHub through RStudio 1.2 Intro to R &amp; RStudio R is the pheromone to RStudio's PDA R is the pheromone to RStudio's PDA. R is a language, specifically, a programming language; it's the way you can speak to your computer to ask it to carry out certain computations. RStudio is an integrated development environment (IDE). This means it is basically an interface, albeit a fancy one, that makes it easier to communicate with your computer in the language R. The main benefit is the additional features it has that enable you to more efficiently speak R. Note R and RStudio are two different pieces of software; for this course you are expected to download both. As you'd expect, the PDA depends on the pheromones (i.e., RStudio depends on R) so you have to download R to use RStudio! 1.2.1 Why? R It's free It's open source A general-purpose of programming language Written by statisticians (here in Auckland!) It's available for all operating systems (Windows, Linux, and Mac) There is a huge online support network It's extremely flexible; if you can code it you can do it! 15,000+ packages available! ... RStudio &quot;If R were an airplane, RStudio would be the airport...&quot; --- Julie Lowndes, Introduction to RStudio Awesomeness Speaks nicely to R Tab completion Debugging capabilities There is a huge online support network Offers many other features and tools to make your workflow with R easier It facilitates reproducibility ... 1.2.2 Installing R and RStudio As mentioned above RStudio depends on R so there is an order you should follow when you download these software. Download and install R by following these instructions. Make sure you choose the correct operating system. Download and install RStudio by going here choosing RStudio Desktop Open Source License Free and following instructions. Check all is working Open up RStudio from your computer menu, the icon will look something like this (DO NOT use this icon , this is a link to R and will only open a very basic interface) Wait a little and you should see RStudio open up to something similar to the screenshot below Pay close attention to the notes in the screenshot and familiarise yourself with the terms. Finally, in the Console next to the prompt type 1:10 and press enter on your keyboard. Your computer should say something back you (in the Console)! What do you think you were asking it to do? Does the output make sense?1 1.3 Getting started As in step 3. above open up RStudio from your computer menu, the icon will look something like this . Using the diagram above identify the different panes: Console where you directly type command in and communicate with your computer (via the language R). Environment pane Files pane Some terminology Running code: the act of telling R to perform an act by giving it commands in the console. Objects: where values are saved in (see later for creating an object. Script: a text file containing a set of commands and comments. Comments: notes written within a Script to better document/explain what's happening 1.3.1 R errors üò± data &lt;- read.csv(&quot;data_file_not_in_my_working_directory.csv&quot;) ## Warning in file(file, &quot;rt&quot;): cannot open file ## &#39;data_file_not_in_my_working_directory.csv&#39;: No such file or directory ## Error in file(file, &quot;rt&quot;): cannot open the connection library(some_library_I_have_not_installed) ## Error in library(some_library_I_have_not_installed): there is no package called &#39;some_library_I_have_not_installed&#39; some_function_I_spelled_worng(x = x) ## Error in some_function_I_spelled_worng(x = x): could not find function &quot;some_function_I_spelled_worng&quot; an_object_I_have_not_created ## Error in eval(expr, envir, enclos): object &#39;an_object_I_have_not_created&#39; not found What do you think the issues are here üòâ 1.3.2 R Scripts (a .r file) Go File &gt; New File &gt; R Script to open up a new Script If you had only three panes showing before, a new (fourth) pane should open up in the top left of RStudio. This file will have a .r extension and is where you can write, edit, and save the R commands you write. It's a dedicated text editor for your R code (very useful if you want to save your code to run at a later date). The main difference between typing your code into a Script vs Console is that you edit it and save it for later! Remember though the Console is the pane where you communicate with your computer so all code you write will have to be Run here. There are two ways of running a line of code you've written in your Script Ensure your cursor is on the line of code you want to run, hold down Ctrl and press Enter. Ensure your cursor is on the line of code you want to run, then use your mouse to click the Run button (it has a green arrow next to it) on the top right of the Script pane. Type 1:10 in your Script and practise running this line of code using both methods above. Not that if you've Run the code successfully then your computer will speak back to you each time via the Console 1.3.3 Writing Comments Comments are notes to yourself (future or present) or to someone else and are, typically, written interspersed in your code. Now, the comments you write will typically be in a language your computer doesn't understand (e.g., English). So that you can write yourself notes in your Script you need to tell your computer using the R language to ignore them. To do this precede any note you write with #, see below. The # is R for ignore anything after this character. ## IGNORE ME ## I&#39;m a comment ## I repeat I&#39;m a comment ## I am not a cat ## OK let&#39;s run some code 2 + 2 ## [1] 4 ## Hmm maybe I should check this ## @kareem_carr ;-) Now remember when you want to leave your R session you'll need to Save your Script to use it again. To do this go File &gt; Save As and name your file what you wish (remember too to choose a relevant folder on your computer, or as recommended use the .Rproj set-up as above). 1.3.4 Change the RStudio appearance up to your taste Go to Tools &gt; Global Options &gt; Apperance 1.4 Reproducible research Keep all similar files for the same analysis in the same place NEVER change raw data 1.4.1 Good practice Always start with a clean workspace Why? So your ex (code) can't come and mess up your life! Go to Tools &gt; Global Options Project-oriented workflow. Recommended: .Rproj Organised Set up each Each assignment/university course as a project Self-contained a project is a folder that contains all relevant files All paths can then be relative to that project Reproducible the project should just work on a different computer Got to Project (top right) &gt; New Project &gt; Create Project Project set-up ‚ö†Ô∏èWarning‚ö†Ô∏è Jenny Bryan will set your computer on fire üî• if you start your script like this rm(list = ls()) This does NOT create a fresh R process it makes your script vulnerable it will come back to bite you 1.4.2 Version control 1.5 git and GitHub All workshops will use these tools git the software &quot;Track Changes features from Microsoft Word on steroids&quot; --- Jenny Bryan a version control system manages the evolution of a set of files (tidily) GitHub an online hosting service &quot;Think of it as DropBox but much, much better&quot; --- Jenny Bryan home for your Git-based projects on the internet 1.5.1 Setup TL;DR Register an account with GitHub https://github.com Make sure you've got the latest version of R R.version.string ## [1] &quot;R version 4.0.3 (2020-10-10)&quot; Upgrade RStudio to the new preview version (optional) Install git: follow these instructions Get started 1.6 Exploratory Data Analysis or EDA we will be using tidyverse. 'tidyverse' is a collection of R packages that all share underlying design philosophy, grammar, and data structures. They are specifically designed to make data wrangling, manipulation, visualisation, and analysis simpler. 1.6.1 Starting out with tidyverse Artwork by [@allison_horst](https://github.com/allisonhorst/) Starting out with tidyverse To install all the packages that belong to the tidyverse run ## request (download) the tidyverse packages from the centralised library install.packages(&quot;tidyverse&quot;) To tell your computer to access the tidyverse functionality in your session run (Note you'll have to do this each time you start up an R session): ## Get the tidyverse packages from our local library library(tidyverse) 1.6.2 Reading in data from a .csv file First off download the paua.csv file from CANVAS To read the data into RStudio In the Environment pane click Import Dataset &gt; ** From Text (readr)** &gt; Browse &gt; Choose your file, remembering which folder you downloaded it to. this is where .Rproj is useful &gt; Another pane should pop up, check the data looks as you might expect &gt; Import Or paua &lt;- read_csv(&quot;paua.csv&quot;) 1.6.3 Explore your data Let's have a look at your data in the Console paua ## # A tibble: 60 x 3 ## Species Length Age ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Haliotis iris 1.8 1.50 ## 2 Haliotis australis 5.4 11.9 ## 3 Haliotis australis 4.8 5.42 ## 4 Haliotis iris 5.75 4.50 ## 5 Haliotis iris 5.65 5.50 ## 6 Haliotis iris 2.8 2.50 ## 7 Haliotis australis 5.9 6.49 ## 8 Haliotis iris 3.75 5.00 ## 9 Haliotis australis 7.2 8.56 ## 10 Haliotis iris 4.25 5.50 ## # ‚Ä¶ with 50 more rows 1.6.4 Explore your data Using the glimpse() command for an alternative view glimpse(paua) ## Rows: 60 ## Columns: 3 ## $ Species &lt;chr&gt; &quot;Haliotis iris&quot;, &quot;Haliotis australis&quot;, &quot;Haliotis australis&quot;, ‚Ä¶ ## $ Length &lt;dbl&gt; 1.80, 5.40, 4.80, 5.75, 5.65, 2.80, 5.90, 3.75, 7.20, 4.25, 6‚Ä¶ ## $ Age &lt;dbl&gt; 1.497884, 11.877010, 5.416991, 4.497799, 5.500789, 2.500972, ‚Ä¶ 1.6.5 The pipe operator %&gt;% A nifty tidyverse tool is called the pipe operator %&gt;%. The pipe operator allows us to combine multiple operations in R into a single sequential chain of actions. Say you would like to perform a hypothetical sequence of operations on a hypothetical data frame x using hypothetical functions f(), g(), and h(): Take x then Use x as an input to a function f() then Use the output of this as an input to a function g() then Use the output of this as an input to a function h() So to calculate the mean Age of each Species in the paua dataset we would use paua %&gt;% group_by(Species) %&gt;% summarize(mean_age = mean(Age)) ## # A tibble: 2 x 2 ## Species mean_age ## * &lt;chr&gt; &lt;dbl&gt; ## 1 Haliotis australis 7.55 ## 2 Haliotis iris 4.40 You would read the sequence above as: Take the paua data.frame then Use this and apply the group_by() function to group by Species Use this output and apply the summarize() function to calculate the mean Age of each group (Species), calling the resulting number mean_age Or to describe my daily routine... I %&gt;% wake_up(time = &quot;later than I should&quot;) %&gt;% give(who = &quot;Watson&quot; , what = &quot;medication&quot;) %&gt;% make(who= &quot;myself&quot;, what = &quot;coffee&quot;) %&gt;% drink() %&gt;% try(remember_what_I_have_on(date = &quot;today&quot;)) Have a go at writing your own! 1.7 Other resources R for Data Science RStudio Education An Introduction to R R for Biologists The Popularity of Data Science Software Happy Git and GitHub for the useR Artwork by @allison_horst You should have seen the numbers 1 to 10 printed out as a sequence.‚Ü© "],["mƒÅori-data-sovereignty-principles.html", "2 MƒÅori Data Sovereignty principles 2.1 Learning objectives 2.2 MƒÅori Data Sovereignty principles 2.3 MƒÅori Data Sovereignty principles 2.4 Resources", " 2 MƒÅori Data Sovereignty principles ''Data sovereignty is the idea that data are subject to the laws and governance structures within the nation it is collected'' 2.1 Learning objectives Define data sovereignty and explain this in relation to a researcher's obligation when collecting, displaying, and analysing data Define and discuss MƒÅori Data Sovereignty principles 2.2 MƒÅori Data Sovereignty principles &quot;For Indigenous peoples, historical encounters with statistics have been fraught, and none more so than when involving official data produced as part of colonial attempts at statecraft.&quot; --- Lovett, R., Lee, V., Kukutai, T., Cormack, D., Rainie, S.C. and Walker, J., 2019. Good data practices for Indigenous data sovereignty and governance. Good data, pp.26-36. &quot;MƒÅori Data Sovereignty has emerged as a critical policy issue as Aotearoa New Zealand develops world-leading linked administrative data resources.&quot; --- Andrew Sporle, Maui Hudson, Kiri West. Chapter 5, Indigenous Data Sovereignty and Policy 2.3 MƒÅori Data Sovereignty principles ‚ÄúMƒÅori data refers to data produced by MƒÅori or that is about MƒÅori and the environments we have relationships with.&quot; --- Te Mana Raraunga Charter Data is a ‚Äúpotential taonga, something precious that needs to be maintained, in relation to its utility‚Äù --- Dr W. Edwards, TMR website MƒÅori Data Sovereignty principles to inform the recognition of MƒÅori rights and interests in data, and the ethical use of data to enhance MƒÅori well-being: Rangatiratanga, authority MƒÅori have an inherent right to exercise control over MƒÅori data and MƒÅori data ecosystems. This right includes, but is not limited to, the creation, collection, access, analysis, interpretation, management, security, dissemination, use and reuse of MƒÅori data. Decisions about the physical and virtual storage of MƒÅori data shall enhance control for current and future generations. Whenever possible, MƒÅori data shall be stored in Aotearoa New Zealand. MƒÅori have the right to data that is relevant and empowers sustainable self-determination and effective self-governance Whakapapa, relationships All data has a whakapapa (genealogy). Accurate metadata should, at minimum, provide information about the provenance of the data, the purpose(s) for its collection, the context of its collection, and the parties involved. The ability to disaggregate MƒÅori data increases its relevance for MƒÅori communities and iwi. MƒÅori data shall be collected and coded using categories that prioritise MƒÅori needs and aspirations. Current decision-making over data can have long-term consequences, good and bad, for future generations of MƒÅori. A key goal of MƒÅori data governance should be to protect against future harm. Whanaungatanga, obligations Individuals‚Äô rights (including privacy rights), risks and benefits in relation to data need to be balanced with those of the groups of which they are a part. In some contexts, collective MƒÅori rights will prevail over those of individuals. Individuals and organisations responsible for the creation, collection, analysis, management, access, security or dissemination of MƒÅori data are accountable to the communities, groups and individuals from whom the data derive Kotahitanga, collective benefit Data ecosystems shall be designed and function in ways that enable MƒÅori to derive individual and collective benefit. Build capacity. MƒÅori Data Sovereignty requires the development of a MƒÅori workforce to enable the creation, collection, management, security, governance and application of data. Connections between MƒÅori and other Indigenous peoples shall be supported to enable the sharing of strategies, resources and ideas in relation to data, and the attainment of common goals. Manaakitanga, reciprocity The collection, use and interpretation of data shall uphold the dignity of MƒÅori communities, groups and individuals. Data analysis that stigmatises or blames MƒÅori can result in collective and individual harm and should be actively avoided. Free, prior and informed consent shall underpin the collection and use of all data from or about MƒÅori. Less defined types of consent shall be balanced by stronger governance arrangements. Kaitiakitanga, guardianship MƒÅori data shall be stored and transferred in such a way that it enables and reinforces the capacity of MƒÅori to exercise kaitiakitanga over MƒÅori data. Ethics. Tikanga, kawa (protocols) and mƒÅtauranga (knowledge) shall underpin the protection, access and use of MƒÅori data. MƒÅori shall decide which MƒÅori data shall be controlled (tapu) or open (noa) access. 2.4 Resources Why data sovereignty matters Indigenous Data Sovereignty and Policy Principles of MƒÅori Data Sovereignty Good data practices for Indigenous data sovereignty and governance. "],["data-wrangling-and-vizualisation.html", "3 Data wrangling and vizualisation 3.1 Learning objectives 3.2 Common dataframe manipulations in the tidyverse 3.3 Data Viz 3.4 Ten Simple Rules for Better Figures 3.5 ggplot2 3.6 Resources", " 3 Data wrangling and vizualisation 3.1 Learning objectives Carry out, and interpret the outputs of, basic exploratory data analysis using in-built R functions Discuss the ethics of data vizualisation Create and communicate informative data visualisations using R Discuss and critique data visualisations 3.2 Common dataframe manipulations in the tidyverse 3.2.1 Using dplyr and tidyr tidy data &quot;Tidy datasets are all alike, but every messy dataset is messy in its own way.&quot; --- Hadley Wickham There are three interrelated rules which make a dataset tidy: Each variable must have its own column Each observation must have its own row Each value must have its own cell [illustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst Why ensure that your data is tidy? Consistency: using a consistent format aids learning and reproducibility Simplicity: it's a format that is well understood by R &quot;Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets.&quot; --- Hadley Wickham, Tidy data 3.2.2 Introuducing the Palmer penguins library(palmerpenguins) ## contains some nice penguin data penguins ## # A tibble: 344 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torge‚Ä¶ 39.1 18.7 181 3750 ## 2 Adelie Torge‚Ä¶ 39.5 17.4 186 3800 ## 3 Adelie Torge‚Ä¶ 40.3 18 195 3250 ## 4 Adelie Torge‚Ä¶ NA NA NA NA ## 5 Adelie Torge‚Ä¶ 36.7 19.3 193 3450 ## 6 Adelie Torge‚Ä¶ 39.3 20.6 190 3650 ## 7 Adelie Torge‚Ä¶ 38.9 17.8 181 3625 ## 8 Adelie Torge‚Ä¶ 39.2 19.6 195 4675 ## 9 Adelie Torge‚Ä¶ 34.1 18.1 193 3475 ## 10 Adelie Torge‚Ä¶ 42 20.2 190 4250 ## # ‚Ä¶ with 334 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; So, what does this show us? A tibble: 344 x 8: A tibble is a specific kind of data frame in R. The penguin dataset has 344 rows (i.e., 344 different observations). Here, each observation corresponds to a penguin. 8 columns corresponding to 3 variables describing each observation. species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex, and year are the different variables of this dataset. We then have a preview of the first 10 rows of observations corresponding to the first 10 penguins. ``... with 334 more rows indicates there are 334 more rows to see, but these have not been printed (likely as it would clog our screen) To learn more about the penguins read the paper that talks all about the data collection. 3.2.3 Common dataframe manipulations in the tidyverse, using dplyr and tidyr Even from these first few rows of data we can see that there are some NA values. Let's count the number of NAs. Remember the %&gt;% operator? Here we're going to be introduced to a few new things the apply() function, the is.na() function, and how R deals with logical values! library(tidyverse) penguins %&gt;% apply(.,2,is.na) %&gt;% apply(.,2,sum) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex year ## 2 2 11 0 There's lot going on in that code! Let's break it down Take penguins then Use penguins as an input to the apply() function (this is specified as the first argument using the .) Now the apply() function takes 3 arguments: the data object you want it to apply something to (in our case penguins) the margin you want to apply that something to; 1 stands for rows and 2 stands for columns, and the function you want it to apply (in our case is.na()). So the second line of code is asking R to apply the is.na() function over the columns of penguins is.na() asks for each value it's fed is it an NA value; it returns a TRUE if so and a FALSE otherwise The output from the first apply() is then fed to the second apply() (using the .). The sum() function then add them up! R treats a TRUE as a 1 and a FALSE as a 0. So how many NAs do you think there are! Doesn't help much. To Now we know there are NA values throughout the data let's remove then and create a new NA free version called penguins_nafree. There is a really handy tidyverse (dplyr) function for this! penguins_nafree &lt;- penguins %&gt;% drop_na() penguins_nafree ## # A tibble: 333 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torge‚Ä¶ 39.1 18.7 181 3750 ## 2 Adelie Torge‚Ä¶ 39.5 17.4 186 3800 ## 3 Adelie Torge‚Ä¶ 40.3 18 195 3250 ## 4 Adelie Torge‚Ä¶ 36.7 19.3 193 3450 ## 5 Adelie Torge‚Ä¶ 39.3 20.6 190 3650 ## 6 Adelie Torge‚Ä¶ 38.9 17.8 181 3625 ## 7 Adelie Torge‚Ä¶ 39.2 19.6 195 4675 ## 8 Adelie Torge‚Ä¶ 41.1 17.6 182 3200 ## 9 Adelie Torge‚Ä¶ 38.6 21.2 191 3800 ## 10 Adelie Torge‚Ä¶ 34.6 21.1 198 4400 ## # ‚Ä¶ with 323 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; Below are some other useful manipulation functions; have a look at the outputs and run them yourselves and see if you can work out what they're doing. filter(penguins_nafree, island == &quot;Torgersen&quot; ) ## # A tibble: 47 x 8 ## species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torge‚Ä¶ 39.1 18.7 181 3750 ## 2 Adelie Torge‚Ä¶ 39.5 17.4 186 3800 ## 3 Adelie Torge‚Ä¶ 40.3 18 195 3250 ## 4 Adelie Torge‚Ä¶ 36.7 19.3 193 3450 ## 5 Adelie Torge‚Ä¶ 39.3 20.6 190 3650 ## 6 Adelie Torge‚Ä¶ 38.9 17.8 181 3625 ## 7 Adelie Torge‚Ä¶ 39.2 19.6 195 4675 ## 8 Adelie Torge‚Ä¶ 41.1 17.6 182 3200 ## 9 Adelie Torge‚Ä¶ 38.6 21.2 191 3800 ## 10 Adelie Torge‚Ä¶ 34.6 21.1 198 4400 ## # ‚Ä¶ with 37 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; summarise(penguins_nafree, avgerage_bill_length = mean(bill_length_mm)) ## # A tibble: 1 x 1 ## avgerage_bill_length ## &lt;dbl&gt; ## 1 44.0 group_by(penguins_nafree, species) ## # A tibble: 333 x 8 ## # Groups: species [3] ## species island bill_length_mm bill_depth_mm flipper_length_‚Ä¶ body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torge‚Ä¶ 39.1 18.7 181 3750 ## 2 Adelie Torge‚Ä¶ 39.5 17.4 186 3800 ## 3 Adelie Torge‚Ä¶ 40.3 18 195 3250 ## 4 Adelie Torge‚Ä¶ 36.7 19.3 193 3450 ## 5 Adelie Torge‚Ä¶ 39.3 20.6 190 3650 ## 6 Adelie Torge‚Ä¶ 38.9 17.8 181 3625 ## 7 Adelie Torge‚Ä¶ 39.2 19.6 195 4675 ## 8 Adelie Torge‚Ä¶ 41.1 17.6 182 3200 ## 9 Adelie Torge‚Ä¶ 38.6 21.2 191 3800 ## 10 Adelie Torge‚Ä¶ 34.6 21.1 198 4400 ## # ‚Ä¶ with 323 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; Often we want to summarise variables by different groups (factors). Below we Take the penguins_nafree data then Use this and apply the group_by() function to group by species Use this output and apply the summarize() function to calculate the mean (using (mean()) bill length (bill_length_mm) of each group (species), calling the resulting number avgerage_bill_length penguins_nafree %&gt;% group_by(species) %&gt;% summarise(avgerage_bill_length = mean(bill_length_mm)) ## # A tibble: 3 x 2 ## species avgerage_bill_length ## * &lt;fct&gt; &lt;dbl&gt; ## 1 Adelie 38.8 ## 2 Chinstrap 48.8 ## 3 Gentoo 47.6 We can also group by multiple factors, for example, penguins_nafree %&gt;% group_by(island,species) %&gt;% summarise(avgerage_bill_length = mean(bill_length_mm)) ## `summarise()` has grouped output by &#39;island&#39;. You can override using the `.groups` argument. ## # A tibble: 5 x 3 ## # Groups: island [3] ## island species avgerage_bill_length ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Biscoe Adelie 39.0 ## 2 Biscoe Gentoo 47.6 ## 3 Dream Adelie 38.5 ## 4 Dream Chinstrap 48.8 ## 5 Torgersen Adelie 39.0 3.3 Data Viz &quot;...have obligations in that we have a great deal of power over how people ultimately make use of data, both in the patterns they see and the conclusions they draw.&quot; --- Michael Correll, Ethical Dimensions of Visualization Research &quot;Clutter and confusion are not attributes of data - they are shortcomings of design.&quot; --- Edward Tufte 3.3.1 Exploratory and explanatory plots Exploratory plots (for you) data exploration doesn't have to look pretty just needs to get to the point explore and discover new data facets formulate new questions For example, Explanatory plots (for others), most common kind of graph used in scientific publications clear purpose designed for the audience make it easy to read (this covers a lot of things) do not distort guide the reader to a particular conclusion answer a specific question support a decision For example, Plots by Cedric Scherer and mentioned on this blog 3.4 Ten Simple Rules for Better Figures &quot;Scientific visualization is classically defined as the process of graphically displaying scientific data. However, this process is far from direct or automatic. There are so many different ways to represent the same data: scatter plots, linear plots, bar plots, and pie charts, to name just a few. Furthermore, the same data, using the same type of plot, may be perceived very differently depending on who is looking at the figure. A more accurate definition for scientific visualization would be a graphical interface between people and data.&quot; --- Nicolas P. Rougier, Michael Droettboom, Philip E. Bourne, Ten Simple Rules for Better Figures Know Your Audience Identify Your Message Adapt the Figure to the Support Medium Captions Are Not Optional Do Not Trust the Defaults Use Color Effectively Do Not Mislead the Reader There are formulas to measure how misleading a graph is! Avoid Chartjunk Message Trumps Beauty &quot;message and readability of the figure is the most important aspect while beauty is only an option&quot; --- Nicolas P. Rougier, Michael Droettboom, Philip E. Bourne, Ten Simple Rules for Better Figures Get the Right Tool I'm an advocate for R üòâ 3.5 ggplot2 ggplot2 is an R package for producing statistical, or data, graphics; it has an underlying grammar based on the Grammar of Graphics Every ggplot2 plot has three key components: data, A set of aesthetic mappings between variables in the data and visual properties, and At least one layer which describes how to render each observation. Layers are usually created with a geom function. 3.5.1 ggplot2 layers 3.5.2 Examples Scatter plot using geom_point() ggplot(penguins,aes(x = body_mass_g, y = flipper_length_mm)) + ## data &amp; aesthetics geom_point() + ## geom geom_smooth(method = &#39;lm&#39;, se = FALSE) ## statistics (linear regression line) Boxplot using geom_boxplot() ggplot(penguins,aes(x = species, y = flipper_length_mm)) + ## data &amp; aesthetics geom_boxplot() + ## geom ggtitle(&quot;Flipper length (mm) by species&quot;) + ylab(&quot;Flipper length (mm)&quot;) + xlab(&quot;Species&quot;) + theme_dark() ## theme Scatter plot specifying color using geom_point() ggplot(penguins,aes(x = body_mass_g, y = flipper_length_mm, color = species)) + ## data and aesthetics geom_point() + ## geom geom_smooth(method = &#39;lm&#39;, se = FALSE) ## statistic (linear regression line without intervals) 3.5.3 The Good, the Bad, and the Ugly... box &lt;- ggplot(penguins,aes(x = species, y = flipper_length_mm)) + ## data &amp; aesthetics geom_boxplot() + ## geom ggtitle(&quot;Flipper length (mm) by species&quot;) + ylab(&quot;Flipper length (mm)&quot;) + xlab(&quot;Species&quot;) + theme_dark() ## theme box jitter &lt;- ggplot(penguins,aes(x = species, y = flipper_length_mm)) + ## data &amp; aesthetics geom_jitter() + ## geom ggtitle(&quot;Flipper length (mm) by species&quot;) + ylab(&quot;Flipper length (mm)&quot;) + xlab(&quot;Species&quot;) + theme_dark() ## theme jitter violin &lt;- ggplot(penguins,aes(x = species, y = flipper_length_mm)) + ## data &amp; aesthetics geom_violin() + ## geom ggtitle(&quot;Flipper length (mm) by species&quot;) + ylab(&quot;Flipper length (mm)&quot;) + xlab(&quot;Species&quot;) + theme_dark() ## theme violin ggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) + geom_point() + geom_smooth(method = &quot;lm&quot;, col = &quot;blue&quot;, se = FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; ggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm, col = species)) + geom_point(size = 2, alpha = 0.5) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + facet_grid(~ sex) + theme_bw() + labs(title = &quot;Flipper Length and Body Mass, by Sex &amp; Species&quot;, subtitle = paste0(nrow(penguins), &quot; of the Palmer Penguins&quot;), x = &quot;Body Mass (g)&quot;, y = &quot;Flipper Length (mm)&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; penguins_nafree &lt;- penguins %&gt;% drop_na() ggplot(penguins_nafree, aes(x = body_mass_g, y = flipper_length_mm, col = species)) + geom_point(size = 2, alpha = 0.5) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + facet_grid(~ sex) + theme_bw() + labs(title = &quot;Flipper Length and Body Mass, by Sex &amp; Species&quot;, subtitle = paste0(nrow(penguins_nafree), &quot; of the Palmer Penguins&quot;), x = &quot;Body Mass (g)&quot;, y = &quot;Flipper Length (mm)&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; 3.6 Resources ggplot2 cheatsheet Elegant Graphics for Data Analysis Using ggplot2 to communicate your results Interesting blogs on graphs in the media tidyverse Tidy Data Palmer penguins "],["introduction-to-the-design-and-analysis-of-experiments.html", "4 Introduction to the design and analysis of experiments 4.1 Learning Objectives 4.2 Key phrases 4.3 Three key principles: 4.4 One-Way Analysis of Variance (ANOVA) 4.5 Analysis of a Completely Randomised Design in R: aov() and lm() 4.6 üò± p-values üò± 4.7 Terminology and issues 4.8 Resources", " 4 Introduction to the design and analysis of experiments 4.1 Learning Objectives Identify the following experimental unit observational units List and describe the three main principals of experimental design Randomization Replication Blocking Calculate Sums of Squares (between and within groups) given the observations Define and state the appropriate degrees of freedom in a one-way ANOVA scenario Calculate the F-statistics given the appropriate Sums of Squares and degrees of freedom Interpret and discuss a given p-value in the context of a stated hypothesis test Explain between group and within group variation Describe a Completely Randomised (experimental) Design Carry out linear regression in R with one categorical explanatory variable (one-way ANOVA) and draw the appropriate inference Communicate statistical concepts and experimental outcomes clearly using language appropriate for both a scientific and non-scientific audience 4.2 Key phrases Experimental unit Smallest portion of experimental material which is independently perturbed Treatment The experimental condition independently applied to an experimental unit Observational unit The smallest unit on which a response is measured. If one measurement is made on each rat: Observational unit = Experimental unit. If Multiple measurements are made on each rat: Each experimental unit has &gt;1 observational unit (pseudo- or technical replication). 4.3 Three key principles: 4.3.1 Replication Biological replication: each treatment is independently applied to each of several humans, animals or plants To generalize results to population Technical replication: two or more samples from the same biological source which are independently processed Advantageous if processing steps introduce a lot of variation Increases the precision with which comparisons of relative abundances between treatments are made Pseudo-replication: one sample from the same biological source, divided into two or more aliquots which are independently measured Advantageous for noisy measuring instruments Increases the precision with which comparisons of relative abundances between treatments are made 4.3.2 Randomization Protects against bias Plan the experiment in such a way that the variations caused by extraneous factors can all be combined under the general heading of &quot;chance&quot;. Ensures that each treatment has the same probability of getting good (or bad) units and thus avoids systematic bias random allocation can cancel out population bias; it ensures that any other possible causes for the experimental results are split equally between groups typically statistical analysis assumes that observations are independent. This is almost never strictly true in practice but randomisation means that our estimates will behave as if they were based on independent observations 4.3.3 Blocking Blocking helps control variability by making treatment groups more alike. Experimental units are divided into subsets (called blocks) so that units within the same block are more similar than units from different subsets or blocks. Blocking is a technique for dealing with nuisance factors. A nuisance factor is a factor that has some effect on the response, but is of no interest (e.g., age class). 4.4 One-Way Analysis of Variance (ANOVA) 4.4.1 Between group SS (SSB) The idea: Assess distances between treatment (surgical condition) means relative to our uncertainty about the actual (true) treatment means. add up the differences: -1.192 + -0.703 + 1.895 = 0. This is always the case! So adding up the differences: -1.192 + -0.703 + 1.895 = 0. Not a great way to measure distances! Sums of Squares? \\(-1.192^2 + -0.703^2 + 1.895^2\\) add up the squared differences? but... there are 4 observations in each group (treatment) \\(4\\times(-1.192)^2 + 4\\times(-0.703)^2 + 4\\times(1.895)^2\\) This is the Between Groups Sums of Squares or the Between group SS (SSB) So the Between group SS (SSB) = 22.02635 Adding up the differences: -1.192 + -0.703 + 1.895 = 0. This is always the case and that itself gives us information... We only need to know two of the values to work out the third! So we have only 2 bits of unique information; SSB degrees of freedom = 2 4.4.2 Within group SS (SSW) The Within group SS (SSW) arises from the same idea: To assess distances between treatment (surgical condition) means relative to our uncertainty about the actual (true) treatment means. Procedure: Observation - Treatment mean Square the difference Add them up! Within group SS (SSW) unexplained variance 4.4.3 F-statistic Recall the Between group SS (SSB) = 22.02635 So mean SSB = 22.02635 / 2 The within group SS (SSW) = 6.059075 Here we have \\(2\\times 3\\) bits of unique information: within groups degrees of freedom is 9. So mean SSW = 6.059/9 Consider the ratio \\({\\frac {{\\text{variation due to treatments}}}{{\\text{unexplained variance}}}} = {\\frac {{\\text{ mean between-group variability}}}{{\\text{mean within-group variability}}}}\\) \\(=\\frac{\\text{mean SSB}}{\\text{mean SSW}}\\) \\(=\\frac{\\text{MSB}}{\\text{MSW}}\\) = \\(=\\frac{\\text{experimental variance}}{\\text{error variance}}\\) 16.3586975 This is the F-statistic... 4.5 Analysis of a Completely Randomised Design in R: aov() and lm() library(tidyverse) rats &lt;- read_csv(&quot;crd_rats_data.csv&quot;) rats %&gt;% group_by(Surgery) %&gt;% summarise(avg = mean(logAUC)) ## # A tibble: 3 x 2 ## Surgery avg ## * &lt;fct&gt; &lt;dbl&gt; ## 1 C 8.46 ## 2 P 8.95 ## 3 S 11.5 4.5.1 aov() rats_aov &lt;- aov(logAUC ~ Surgery, data = rats) Inference Hypothesis: We test the Null hypothesis, \\(H_0\\), population (Surgery) means are the same on average verses the alternative hypothesis, \\(H_1\\), that at least one differs from the others! Probability of getting an F-statistic at least as extreme as the one we observe (think of the area under the tails of the curve below) p-value Pr(&gt;F)= 0.001 tells us we have sufficient evidence to reject \\(H_0\\) at the 1% level of significance 4.5.2 lm() lm() rats_lm &lt;- lm(logAUC ~ Surgery, data = rats) Inference summary(rats_lm)$coef ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.4600 0.4102531 20.6214144 6.930903e-09 ## SurgeryP 0.4900 0.5801856 0.8445574 4.202408e-01 ## SurgeryS 3.0875 0.5801856 5.3215734 4.799872e-04 Which pairs of means are different? Pair-wise comparisons of means Use two-sample t-tests We need to calculate our observed t-value where \\(\\text{t-value} = \\frac{\\text{Sample Difference}_{ij} - \\text{Difference assuming } H_0 \\text{ is true}_{ij}}{\\text{SE of } \\text{Sample Difference}_{ij}}\\) where \\(\\text{Sample Difference}_{ij}\\) = Difference between pair of sample means Compute the p-value for observed t-value summary(rats_lm)$coef ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.4600 0.4102531 20.6214144 6.930903e-09 ## SurgeryP 0.4900 0.5801856 0.8445574 4.202408e-01 ## SurgeryS 3.0875 0.5801856 5.3215734 4.799872e-04 (Intercept) = \\(\\text{mean}_C\\) = 8.46 SE of (Intercept) = SE of \\(\\text{mean}_C\\) = SEM = 0.4102531 \\(\\text{Surgery}_P\\) = \\(\\text{mean}_P\\) ‚Äì \\(\\text{mean}_C\\) = 0.49 SE of \\(\\text{Surgery}_P\\) = SE of (\\(\\text{mean}_P\\) - \\(\\text{mean}_C\\) ) = SED = 0.5801856 Hypotheses being tested The t value and Pr (&gt;|t|) are the t - and p-value for testing the null hypotheses: Mean abundance is zero for C population No difference between the population means of P and C No difference between the population means of S and C We're interested in 2 and 3, but not necessarily 1! Two-sample t -tests for pairwise comparisons of means SurgeryP : t value = Estimate √∑ Std.Error = 0.8446; Pr (&gt;|t|) = 0.4202 4.5.2.1 Diagnostic plots gglm::gglm(rats_lm) # Plot the four main diagnostic plots Residuals vs Fitted plot You are basically looking for no pattern or structure in your residuals (e.g., a &quot;starry&quot; night). You definitely don't want to see is the scatter increasing around the zero line (dashed line) as the fitted values get bigger (e.g., think of a trumpet, a wedge of cheese, or even a slice of pizza) which would indicate unequal variances (heteroscedacity). Normal quantile-quantile (QQ) plot This plot shows the sorted residuals versus expected order statistics from a standard normal distribution. Samples should be close to a line; points moving away from 45 degree line at the tails suggest the data are from a skewed distribution. Scale-Location plot (\\(\\sqrt{\\text{|standardized residuals vs Fitted|}}\\)) Another way to check the homoskedasticity (constant-variance) assumption. We want the line to be roughly horizontal. If this is the case then the average magnitude of the standardized residuals isn't changing much as a function of the fitted values. We'd also like the spread around the line not to vary much with the fitted values; then the variability of magnitudes doesn't vary much as a function of the fitted values. Residuals vs Leverage plot (standardized residuals vs Leverage) This can help detect outliers in a linear regression model. For linear regression model leverage measures how sensitive a fitted value is to a change in the true response. We're looking at how the spread of standardized residuals changes as the leverage. This can also be used to detect heteroskedasticity and non-linearity: the spread of standardized residuals shouldn't change as a function of leverage. In addition, points with high leverage may be influential: that is, deleting them would change the model a lot. 4.6 üò± p-values üò± The ASA Statement on p-Values: Context, Process, and Purpose &quot;Good statistical practice, as an essential component of good scientific practice, emphasizes principles of good study design and conduct, a variety of numerical and graphical summaries of data, understanding of the phenomenon under study, interpretation of results in context, complete reporting and proper logical and quantitative understanding of what data summaries mean. No single index should substitute for scientific reasoning.&quot; --- ASA Statement on p-Values What is a p-Value? Informally, a p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value p-values can indicate how incompatible the data are with a specified statistical model p-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold Proper inference requires full reporting and transparency A p-value, or statistical significance, does not measure the size of an effect or the importance of a result By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis 4.7 Terminology and issues Type I error (false positive): declare a difference (i.e., reject \\(H_0\\)) when there is no difference (i.e. \\(H_0\\) is true). Risk of the Type I error is determined by the level of significance (which we set!) (i.e., \\(\\alpha =\\text{ P(Type I error)} = \\text{P(false positive)}\\). Type II error (false negative): difference not declared (i.e., \\(H_0\\) not rejected) when there is a difference (i.e., \\(H_0\\) is false). Let \\(\\beta =\\) P(do not reject \\(H_0\\) when \\(H_0\\) is false); so, \\(1-\\beta\\) = P(reject \\(H_0\\) when \\(H_0\\) is false) = P(a true positive), which is the statistical power of the test. Each time we carry out a hypothesis test the probability we get a false positive result (type I error) is given by \\(\\alpha\\) (the level of significance we choose). When we have multiple comparisons to make we should then control the Type I error rate across the entire family of tests under consideration, i.e., control the Family-Wise Error Rate (FWER); this ensures that the risk of making at least one Type I error among the family of comparisons in the experiment is \\(\\alpha\\). State of Nature Don't reject \\(H_0\\) reject \\(H_0\\) \\(H_0\\) is true ‚úÖ Type I error \\(H_0\\) is false Type II error ‚úÖ 4.8 Resources Looking forward Traditional name Model formula R code Simple regression \\(Y \\sim X_{continuous}\\) lm(Y ~ X) One-way ANOVA \\(Y \\sim X_{categorical}\\) lm(Y ~ X) Two-way ANOVA \\(Y \\sim X1_{categorical} + X2_{categorical}\\) lm(Y ~ X1 + X2) ANCOVA \\(Y \\sim X1_{continuous} + X2_{categorical}\\) lm(Y ~ X1 + X2) Multiple regression \\(Y \\sim X1_{continuous} + X2_{continuous}\\) lm(Y ~ X1 + X2) Factorial ANOVA \\(Y \\sim X1_{categorical} * X2_{categorical}\\) lm(Y ~ X1 * X2) or lm(Y ~ X1 + X2 + X1:X2) Glass, David J. Experimental Design for Biologists. Second ed. 2014. Print. Welham, S. J. Statistical Methods in Biology : Design and Analysis of Experiments and Regression. 2015. Print. Fisher, Ronald Aylmer. The Design of Experiments. 8th ed. Edinburgh: Oliver &amp; Boyd, 1966. Print. O &amp; B Paperbacks. "]]
