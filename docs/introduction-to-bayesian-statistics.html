<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Introduction to Bayesian statistics | Advanced Biological Data Analysis</title>
  <meta name="description" content="Introduction to Bayesian statistics | Advanced Biological Data Analysis" />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="Introduction to Bayesian statistics | Advanced Biological Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Bayesian statistics | Advanced Biological Data Analysis" />
  
  
  

<meta name="author" content="University of Auckland" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="example-for-a-continuous-random-variable.html"/>
<link rel="next" href="module-5.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Nau mai, haere mai. Welcome to BIOSCI 738</a></li>
<li class="chapter" data-level="" data-path="useful-information-to-set-you-up-for-your-semester.html"><a href="useful-information-to-set-you-up-for-your-semester.html"><i class="fa fa-check"></i>Useful information to set you up for your semester</a><ul>
<li class="chapter" data-level="" data-path="useful-information-to-set-you-up-for-your-semester.html"><a href="useful-information-to-set-you-up-for-your-semester.html#course-outline"><i class="fa fa-check"></i>Course outline</a></li>
<li class="chapter" data-level="" data-path="useful-information-to-set-you-up-for-your-semester.html"><a href="useful-information-to-set-you-up-for-your-semester.html#learning-outcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="" data-path="useful-information-to-set-you-up-for-your-semester.html"><a href="useful-information-to-set-you-up-for-your-semester.html#course-summary"><i class="fa fa-check"></i>Course summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="module-1.html"><a href="module-1.html"><i class="fa fa-check"></i>Module 1</a><ul>
<li><a href="r-and-rstudio.html#r-and-rstudio"><code>R</code> and <code>RStudio</code></a><ul>
<li class="chapter" data-level="" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html"><i class="fa fa-check"></i>Installing R and RStudio</a></li>
<li class="chapter" data-level="" data-path="r-and-rstudio.html"><a href="r-and-rstudio.html#getting-started"><i class="fa fa-check"></i>Getting started</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="reproducible-research.html"><a href="reproducible-research.html"><i class="fa fa-check"></i>Reproducible research</a><ul>
<li class="chapter" data-level="" data-path="reproducible-research.html"><a href="reproducible-research.html#project-oriented-workflow-good-practice"><i class="fa fa-check"></i>Project-oriented workflow: good practice</a></li>
<li><a href="reproducible-research.html#version-control-with-git-and-github">Version control with <code>git</code> and GitHub</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i>Exploratory Data Analysis</a><ul>
<li><a href="exploratory-data-analysis.html#starting-out-with-tidyverse">Starting out with <code>tidyverse</code></a></li>
<li><a href="exploratory-data-analysis.html#reading-in-data-from-a-.csv-file">Reading in data from a <code>.csv</code> file</a></li>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#explore-your-data"><i class="fa fa-check"></i>Explore your data</a></li>
<li><a href="exploratory-data-analysis.html#the-pipe-operator">The pipe operator <code>%&gt;%</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="māori-data-sovereignty-principles.html"><a href="māori-data-sovereignty-principles.html"><i class="fa fa-check"></i>Māori Data Sovereignty principles</a></li>
<li class="chapter" data-level="" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i>Data wrangling</a><ul>
<li><a href="data-wrangling.html#common-dataframe-manipulations-in-the-tidyverse">Common dataframe manipulations in the <code>tidyverse</code></a></li>
<li><a href="data-wrangling.html#introuducing-the-palmer-penguins">Introuducing the <span>Palmer penguins</span></a></li>
<li><a href="data-wrangling.html#common-dataframe-manipulations-in-the-tidyverse-using-dplyr-and-tidyr">Common dataframe manipulations in the <code>tidyverse</code>, using <code>dplyr</code> and <code>tidyr</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-viz.html"><a href="data-viz.html"><i class="fa fa-check"></i>Data Viz</a><ul>
<li class="chapter" data-level="" data-path="data-viz.html"><a href="data-viz.html#exploratory-and-explanatory-plots"><i class="fa fa-check"></i>Exploratory and explanatory plots</a></li>
<li class="chapter" data-level="" data-path="data-viz.html"><a href="data-viz.html#ten-simple-rules-for-better-figures"><i class="fa fa-check"></i>Ten Simple Rules for Better Figures</a></li>
<li><a href="data-viz.html#ggplot2"><code>ggplot2</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="module-2.html"><a href="module-2.html"><i class="fa fa-check"></i>Module 2</a><ul>
<li class="chapter" data-level="" data-path="key-satistical-concepts.html"><a href="key-satistical-concepts.html"><i class="fa fa-check"></i>Key satistical concepts</a></li>
<li class="chapter" data-level="" data-path="permutation-tests.html"><a href="permutation-tests.html"><i class="fa fa-check"></i>Permutation tests</a><ul>
<li><a href="permutation-tests.html#significance-testing-using-permutation-randomisation-tests">Significance testing using permutation (<em>randomisation</em>) tests</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i>The bootstrap</a><ul>
<li class="chapter" data-level="" data-path="the-bootstrap.html"><a href="the-bootstrap.html#example-constructing-bootstrap-confidence-intervals"><i class="fa fa-check"></i>Example: constructing bootstrap confidence intervals</a></li>
<li class="chapter" data-level="" data-path="the-bootstrap.html"><a href="the-bootstrap.html#differences"><i class="fa fa-check"></i>Differences</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="one-and-two-sample-tests.html"><a href="one-and-two-sample-tests.html"><i class="fa fa-check"></i>One and two sample tests</a><ul>
<li class="chapter" data-level="" data-path="one-and-two-sample-tests.html"><a href="one-and-two-sample-tests.html#one-sample-t-test"><i class="fa fa-check"></i>One-Sample t-test</a></li>
<li class="chapter" data-level="" data-path="one-and-two-sample-tests.html"><a href="one-and-two-sample-tests.html#differences-between-two-means"><i class="fa fa-check"></i>Differences between two means</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i>Linear regression</a><ul>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#some-mathematical-notation"><i class="fa fa-check"></i>Some mathematical notation</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#modeling-bill-depth"><i class="fa fa-check"></i>Modeling Bill Depth</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#single-continuous-variable"><i class="fa fa-check"></i>Single continuous variable</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#one-factor-and-a-continous-variable"><i class="fa fa-check"></i>One factor and a continous variable</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#interactions"><i class="fa fa-check"></i>Interactions</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#other-possible-models"><i class="fa fa-check"></i>Other possible models</a></li>
</ul></li>
<li><a href="tldr-lm.html#tldr-lm">TL;DR <code>lm()</code></a></li>
<li class="chapter" data-level="" data-path="model-comparison-and-selection.html"><a href="model-comparison-and-selection.html"><i class="fa fa-check"></i>Model comparison and selection</a><ul>
<li class="chapter" data-level="" data-path="model-comparison-and-selection.html"><a href="model-comparison-and-selection.html#model-comparison-and-selection-1"><i class="fa fa-check"></i>Model comparison and selection</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="point-predictions-and-confidence-intervals.html"><a href="point-predictions-and-confidence-intervals.html"><i class="fa fa-check"></i>Point predictions and confidence intervals</a><ul>
<li class="chapter" data-level="" data-path="point-predictions-and-confidence-intervals.html"><a href="point-predictions-and-confidence-intervals.html#confidence-intervals-for-parameters"><i class="fa fa-check"></i>Confidence intervals for parameters</a></li>
<li class="chapter" data-level="" data-path="point-predictions-and-confidence-intervals.html"><a href="point-predictions-and-confidence-intervals.html#point-prediction"><i class="fa fa-check"></i>Point prediction</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="p-values-an-intro.html"><a href="p-values-an-intro.html"><i class="fa fa-check"></i>p-values, an intro</a><ul>
<li class="chapter" data-level="" data-path="p-values-an-intro.html"><a href="p-values-an-intro.html#p-values-from-permutation-tests"><i class="fa fa-check"></i>P-values from permutation tests</a></li>
<li class="chapter" data-level="" data-path="p-values-an-intro.html"><a href="p-values-an-intro.html#p-values"><i class="fa fa-check"></i>😱 p-values 😱</a></li>
<li class="chapter" data-level="" data-path="p-values-an-intro.html"><a href="p-values-an-intro.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i>Type I and Type II errors</a></li>
</ul></li>
<li><a href="one-way-analysis-of-variance-anova.html#one-way-analysis-of-variance-anova">One-Way <strong>An</strong>alysis <strong>o</strong>f <strong>Va</strong>riance (ANOVA)</a><ul>
<li class="chapter" data-level="" data-path="one-way-analysis-of-variance-anova.html"><a href="one-way-analysis-of-variance-anova.html"><i class="fa fa-check"></i>Between group SS (SSB)</a></li>
<li class="chapter" data-level="" data-path="one-way-analysis-of-variance-anova.html"><a href="one-way-analysis-of-variance-anova.html#within-group-ss-ssw"><i class="fa fa-check"></i>Within group SS (SSW)</a></li>
<li class="chapter" data-level="" data-path="one-way-analysis-of-variance-anova.html"><a href="one-way-analysis-of-variance-anova.html#f-statistic"><i class="fa fa-check"></i>F-statistic</a></li>
<li class="chapter" data-level="" data-path="one-way-analysis-of-variance-anova.html"><a href="one-way-analysis-of-variance-anova.html#degrees-of-freedom-df"><i class="fa fa-check"></i>Degrees of freedom (DF)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="module-3.html"><a href="module-3.html"><i class="fa fa-check"></i>Module 3</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html"><i class="fa fa-check"></i>Introduction to the design and analysis of experiments</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#key-phrases"><i class="fa fa-check"></i>Key phrases</a></li>
<li class="chapter" data-level="" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#the-three-key-principles"><i class="fa fa-check"></i>The three key principles:</a></li>
<li class="chapter" data-level="" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#replication"><i class="fa fa-check"></i>Replication</a></li>
<li class="chapter" data-level="" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#randomization"><i class="fa fa-check"></i>Randomization</a></li>
<li class="chapter" data-level="" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#blocking"><i class="fa fa-check"></i>Blocking</a></li>
<li class="chapter" data-level="" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#setting-up-an-experiment"><i class="fa fa-check"></i>Setting up an experiment</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="some-basic-experimental-designs.html"><a href="some-basic-experimental-designs.html"><i class="fa fa-check"></i>Some basic experimental designs</a><ul>
<li class="chapter" data-level="" data-path="some-basic-experimental-designs.html"><a href="some-basic-experimental-designs.html#completely-randomised-design-crd"><i class="fa fa-check"></i>Completely randomised design (CRD)</a></li>
<li class="chapter" data-level="" data-path="some-basic-experimental-designs.html"><a href="some-basic-experimental-designs.html#randomised-complete-block-design-rcbd"><i class="fa fa-check"></i>Randomised complete block design (RCBD)</a></li>
<li class="chapter" data-level="" data-path="some-basic-experimental-designs.html"><a href="some-basic-experimental-designs.html#factorial-design"><i class="fa fa-check"></i>Factorial design</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="modler-v.-designer-the-maths.html"><a href="modler-v.-designer-the-maths.html"><i class="fa fa-check"></i>Modler v. designer: the maths</a><ul>
<li class="chapter" data-level="" data-path="modler-v.-designer-the-maths.html"><a href="modler-v.-designer-the-maths.html#a-completely-randomised-design-crd"><i class="fa fa-check"></i>A completely randomised design (CRD)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="module-4.html"><a href="module-4.html"><i class="fa fa-check"></i>Module 4</a><ul>
<li class="chapter" data-level="" data-path="least-squares-estimation.html"><a href="least-squares-estimation.html"><i class="fa fa-check"></i>Least Squares Estimation</a><ul>
<li class="chapter" data-level="" data-path="least-squares-estimation.html"><a href="least-squares-estimation.html#some-basic-matrix-algebra"><i class="fa fa-check"></i>Some basic matrix algebra</a></li>
<li class="chapter" data-level="" data-path="least-squares-estimation.html"><a href="least-squares-estimation.html#matrix-representation-of-a-crd"><i class="fa fa-check"></i>Matrix representation of a CRD</a></li>
<li class="chapter" data-level="" data-path="least-squares-estimation.html"><a href="least-squares-estimation.html#a-numeric-example"><i class="fa fa-check"></i>A numeric example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="maximum-likelkihood-estimation.html"><a href="maximum-likelkihood-estimation.html"><i class="fa fa-check"></i>Maximum likelkihood estimation</a><ul>
<li class="chapter" data-level="" data-path="maximum-likelkihood-estimation.html"><a href="maximum-likelkihood-estimation.html#differeniation-rules"><i class="fa fa-check"></i>Differeniation rules</a></li>
<li class="chapter" data-level="" data-path="maximum-likelkihood-estimation.html"><a href="maximum-likelkihood-estimation.html#logarithn-rules"><i class="fa fa-check"></i>Logarithn rules</a></li>
<li class="chapter" data-level="" data-path="maximum-likelkihood-estimation.html"><a href="maximum-likelkihood-estimation.html#maximum-likelihood"><i class="fa fa-check"></i>Maximum likelihood</a></li>
<li class="chapter" data-level="" data-path="maximum-likelkihood-estimation.html"><a href="maximum-likelkihood-estimation.html#the-likelihood"><i class="fa fa-check"></i>The Likelihood</a></li>
<li class="chapter" data-level="" data-path="maximum-likelkihood-estimation.html"><a href="maximum-likelkihood-estimation.html#maximum-likelihood-for-a-crd"><i class="fa fa-check"></i>Maximum likelihood for a CRD</a></li>
<li class="chapter" data-level="" data-path="maximum-likelkihood-estimation.html"><a href="maximum-likelkihood-estimation.html#maximising-the-log-likelihood"><i class="fa fa-check"></i>Maximising the log-likelihood</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="maximum-likelihood-estimation-for-a-poisson-distribution.html"><a href="maximum-likelihood-estimation-for-a-poisson-distribution.html"><i class="fa fa-check"></i>Maximum likelihood estimation for a Poisson distribution</a><ul>
<li class="chapter" data-level="" data-path="maximum-likelihood-estimation-for-a-poisson-distribution.html"><a href="maximum-likelihood-estimation-for-a-poisson-distribution.html#maximising-the-likelihood"><i class="fa fa-check"></i>Maximising the Likelihood</a></li>
<li class="chapter" data-level="" data-path="maximum-likelihood-estimation-for-a-poisson-distribution.html"><a href="maximum-likelihood-estimation-for-a-poisson-distribution.html#maximising-the-log-likelihood-function"><i class="fa fa-check"></i>Maximising the log-likelihood function</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="example-for-a-continuous-random-variable.html"><a href="example-for-a-continuous-random-variable.html"><i class="fa fa-check"></i>Example for a continuous random variable</a></li>
<li class="chapter" data-level="" data-path="introduction-to-bayesian-statistics.html"><a href="introduction-to-bayesian-statistics.html"><i class="fa fa-check"></i>Introduction to Bayesian statistics</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-bayesian-statistics.html"><a href="introduction-to-bayesian-statistics.html#conditional-probability"><i class="fa fa-check"></i>Conditional probability</a></li>
<li class="chapter" data-level="" data-path="introduction-to-bayesian-statistics.html"><a href="introduction-to-bayesian-statistics.html#bayes-rule"><i class="fa fa-check"></i>Bayes’ rule</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="module-5.html"><a href="module-5.html"><i class="fa fa-check"></i>Module 5</a><ul>
<li class="chapter" data-level="" data-path="beyond-linear-models-to-generalised-linear-models-glms.html"><a href="beyond-linear-models-to-generalised-linear-models-glms.html"><i class="fa fa-check"></i>Beyond Linear Models to Generalised Linear Models (GLMs)</a><ul>
<li class="chapter" data-level="" data-path="beyond-linear-models-to-generalised-linear-models-glms.html"><a href="beyond-linear-models-to-generalised-linear-models-glms.html#counting-animals"><i class="fa fa-check"></i>Counting animals…</a></li>
<li class="chapter" data-level="" data-path="beyond-linear-models-to-generalised-linear-models-glms.html"><a href="beyond-linear-models-to-generalised-linear-models-glms.html#other-modelling-approaches-not-examinable"><i class="fa fa-check"></i>Other modelling approaches (not examinable)</a></li>
<li><a href="beyond-linear-models-to-generalised-linear-models-glms.html#model-formula-syntax"><strong>Model formula</strong> syntax</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction-to-generalised-linear-models-glms.html"><a href="introduction-to-generalised-linear-models-glms.html"><i class="fa fa-check"></i>Introduction to generalised linear models (GLMs)</a></li>
<li class="chapter" data-level="" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i>Poisson regression</a><ul>
<li class="chapter" data-level="" data-path="poisson-regression.html"><a href="poisson-regression.html#an-example-bird-abundance"><i class="fa fa-check"></i>An example: bird abundance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i>Logistic regression</a><ul>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html#an-example-lobsters"><i class="fa fa-check"></i>An example: lobsters</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="a-summary-of-glms.html"><a href="a-summary-of-glms.html"><i class="fa fa-check"></i>A summary of GLMs</a></li>
<li class="chapter" data-level="" data-path="introduction-to-generalised-linear-models-with-random-effects.html"><a href="introduction-to-generalised-linear-models-with-random-effects.html"><i class="fa fa-check"></i>Introduction to generalised linear models with random effects</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="module-6.html"><a href="module-6.html"><i class="fa fa-check"></i>Module 6</a><ul>
<li class="chapter" data-level="" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i>Clustering</a><ul>
<li class="chapter" data-level="" data-path="clustering.html"><a href="clustering.html#partitioning-methods."><i class="fa fa-check"></i>Partitioning methods.</a></li>
<li class="chapter" data-level="" data-path="clustering.html"><a href="clustering.html#hierarchical-methods."><i class="fa fa-check"></i>Hierarchical methods.</a></li>
<li class="chapter" data-level="" data-path="clustering.html"><a href="clustering.html#hierarchical-agglomerative-clustering."><i class="fa fa-check"></i>Hierarchical agglomerative clustering.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tldr.html"><a href="tldr.html"><i class="fa fa-check"></i>TL;DR</a><ul>
<li class="chapter" data-level="" data-path="tldr.html"><a href="tldr.html#clustering-algorithms"><i class="fa fa-check"></i>Clustering algorithms</a></li>
<li><a href="tldr.html#k-means-using-the-palmerpenguins-data">k-means using the <code>palmerpenguins</code> data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tldr-k-means-clustering.html"><a href="tldr-k-means-clustering.html"><i class="fa fa-check"></i>TL;DR k-means clustering</a></li>
<li class="chapter" data-level="" data-path="dimension-reduction.html"><a href="dimension-reduction.html"><i class="fa fa-check"></i>Dimension reduction</a><ul>
<li class="chapter" data-level="" data-path="dimension-reduction.html"><a href="dimension-reduction.html#pca"><i class="fa fa-check"></i>PCA</a></li>
<li class="chapter" data-level="" data-path="dimension-reduction.html"><a href="dimension-reduction.html#reality-check-reducing-noise"><i class="fa fa-check"></i>Reality check: reducing noise…</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multidimensional-scaling-mds.html"><a href="multidimensional-scaling-mds.html"><i class="fa fa-check"></i>Multidimensional Scaling (MDS)</a><ul>
<li class="chapter" data-level="" data-path="multidimensional-scaling-mds.html"><a href="multidimensional-scaling-mds.html#principal-coordinates."><i class="fa fa-check"></i>Principal Coordinates.</a></li>
<li class="chapter" data-level="" data-path="multidimensional-scaling-mds.html"><a href="multidimensional-scaling-mds.html#metric-scaling."><i class="fa fa-check"></i>Metric Scaling.</a></li>
<li class="chapter" data-level="" data-path="multidimensional-scaling-mds.html"><a href="multidimensional-scaling-mds.html#non-metric-scaling."><i class="fa fa-check"></i>Non-metric scaling.</a></li>
<li class="chapter" data-level="" data-path="multidimensional-scaling-mds.html"><a href="multidimensional-scaling-mds.html#which-to-use-metric-or-non-metric"><i class="fa fa-check"></i>Which to use: metric or non-metric?</a></li>
<li><a href="multidimensional-scaling-mds.html#examples-in-r">Examples in <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="non-metric-multidimensional-scaling.html"><a href="non-metric-multidimensional-scaling.html"><i class="fa fa-check"></i>Non-metric Multidimensional Scaling</a><ul>
<li><a href="non-metric-multidimensional-scaling.html#examples-in-r-1">Examples in <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="correspondence-analysis-ca.html"><a href="correspondence-analysis-ca.html"><i class="fa fa-check"></i>Correspondence Analysis (CA)</a></li>
<li class="chapter" data-level="" data-path="mds-summary.html"><a href="mds-summary.html"><i class="fa fa-check"></i>MDS summary</a></li>
<li class="chapter" data-level="" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html"><i class="fa fa-check"></i>Linear Discriminant Analysis (LDA)</a><ul>
<li><a href="linear-discriminant-analysis-lda.html#example-in-r">Example in <code>R</code></a></li>
<li class="chapter" data-level="" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#prediction"><i class="fa fa-check"></i>Prediction</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Biological Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-bayesian-statistics" class="section level2">
<h2>Introduction to Bayesian statistics</h2>
<blockquote>
“Critical thinking is an active and ongoing process. It requires that we all think like Bayesians, updating our knowledge as new information comes in.”
<footer>
— Daniel J. Levitin, A Field Guide to Lies: Critical Thinking in the Information Age
</footer>
</blockquote>
<div id="conditional-probability" class="section level3">
<h3>Conditional probability</h3>
<p>The probability of the event <span class="math inline">\(A\)</span> occuring given that the event <span class="math inline">\(B\)</span> has already occured is <span class="math display">\[P(A∣B) = \frac{P(A \:\text{and}\: B)}{P(B)}\]</span>. This is called a conditional probability. Note that <span class="math inline">\(P(A∣B)\)</span> is not the same as <span class="math inline">\(P(B∣A)\)</span></p>
<p><strong>An example</strong></p>
<p>Rapid antigen (lateral flow) tests are rapid antigen tests used to detect SARS-COV-2 infection (COVID-19). They are very easy to use and a lot less uncomfortable than having a swab for a PCR taken!</p>
<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/COVID-19_rapid_test.jpg/800px-COVID-19_rapid_test.jpg" style="width:20.0%" />
</p>
<p>In summary, the lateral flow test can show a positive (<span class="math inline">\(+\)</span>) or a negative (<span class="math inline">\(-\)</span>) result. The person taking the test either has (infected) or does not have COVID-19 (not infected).</p>
<p><a href="https://doi.org/10.1186/s12879-021-06528-3">It is reported</a> that the average <strong>sensitivity</strong> of the Innova lateral flow tests is <span class="math inline">\(\sim 0.787\)</span>. Breaking this down means that given you have SARS-CoV-2 (Covid19) the chance of a positive lateral flow test is 0.787.</p>
<p>It was also reported that the <strong>specificity</strong> of this test was 0.997. That is, the chance of a negative test given that you do not have COVID-19 is 0.997.</p>
<p>This can be summarised as <span class="math inline">\(P( + | \text{infected}) = 0.787\)</span> and <span class="math inline">\(P( -| \text{not infected}) = 0.997\)</span></p>
<p>What you would probably like to know is given that the test is positive, what is the probability that you have COVID-19? <span class="math inline">\(P( \text{infected}| +) = ?\)</span></p>
<p>Let’s assume that people in the population with COVID-19 is 10% (not far off the estimated % with Omicron in London a few weeks ago); that is, <span class="math inline">\(P(\text{infected}) = 0.1\)</span>.</p>
<p>But, what about <span class="math inline">\(P( \text{infected}| +) ?\)</span></p>
<p>Recall, <span class="math display">\[P(A∣B) = \frac{P(A \:\text{and}\: B)}{P(B)}.\]</span> So,</p>
<p><span class="math display">\[P( \text{infected}| +) = \frac{P(\text{infected} \:\text{and}\: +)}{P(+)}.\]</span></p>
<p>We have, <span class="math inline">\(P(\text{infected} \:\text{and}\: +) = P(\text{infected})\times P( + | \text{infected}) = 0.1 \times 0.787 = 0.0787.\)</span></p>
<p>So, <span class="math inline">\(P(+) = P(\text{infected} \:\text{and}\: +) + P(\text{clear} \:\text{and}\: +) = 0.0787 + ( 0.9 \times (1 - 0.997)) = 0.0787 + ( 0.9 \times 0.003) = 0.0787 + 0.0027 = 0.0814.\)</span></p>
<p>Therefore, <span class="math inline">\(P( \text{infected}| +) = \frac{ 0.0787}{0.0814} = 0.9668305.\)</span></p>
<p>Rearranging,</p>
<p><span class="math display">\[P( \text{infected}| +) = \frac{P( + | \text{infected})P(\text{infected})}{P(+)}.\]</span></p>
</div>
<div id="bayes-rule" class="section level3">
<h3>Bayes’ rule</h3>
<p>Bayes’ theorem, named after British mathematician Reverend Thomas Bayes, is a mathematical formula for determining conditional probability. His work and theorems were presented in <a href="https://en.wikipedia.org/wiki/An_Essay_towards_solving_a_Problem_in_the_Doctrine_of_Chances">An Essay towards solving a Problem in the Doctrine of Chances</a>, this was read to the Royal Society in 1763 after his death.</p>
<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Thomas_Bayes.gif/220px-Thomas_Bayes.gif" alt="The Reverend Thomas Bayes" />
</p>
<p><strong>Theorem, Bayes’ rule</strong> The conditional probability of the event <span class="math inline">\(A\)</span> conditional on the event <span class="math inline">\(B\)</span> is given by</p>
<p><span class="math display">\[P(B|A) = \frac{P(A|B)P(B)}{P(A)}\]</span></p>
<p>Let’s think of this in terms of our data and hypothesis:</p>
<p><span class="math display">\[P(\text{hypothesis}∣\text{data}) = \frac{P(\text{data} | \text{hypothesis} )P(\text{hypothesis})}{P(\text{data})}\]</span></p>
<p>Recall from the previous sections that our hypotheses relate to estimating <strong>parameter</strong> values (e.g., intercepts, differences in means, slopes etc ). The formula above (Bayes’ theorem) calculates the probability of the parameter(s), say <span class="math inline">\(\theta\)</span>, values given the data.</p>
<p>But what is the difference here to maximum likelihood estimation (i.e., MLE, the frequentist approach)?
Taking an MLE approach assumes that the parameters are fixed (i.e., they have one <em>true</em> value); the parameters are unknown and are to be estimated. Using this approach we typically estimate a point estimate of the parameter of interest. Taking a Bayesian approach assumes that the parameters are not fixed. Instead, parameters are assumed to come from some fixed unknown distribution (i;e., a range of plausible values). This approach requires that we have some prior beliefs about the data (even if these beliefs are uninformative). This information is introduces <em>a priori</em> to the modelling framework.</p>
<p><span class="math display">\[P(B|A) = \frac{P(A|B)P(B)}{P(A)}\]</span></p>
<p>Schematically if <span class="math inline">\(A = \theta\)</span> and <span class="math inline">\(B = \text{data}\)</span>, then the above translates to</p>
<p><span class="math display">\[P(\theta∣\text{data}) = \frac{P(\text{data} | \theta )P(\theta)}{P(\text{data})}\]</span></p>
<p>where <span class="math inline">\(P(\theta∣\text{data})\)</span> represents what you know after having seen the data. This is called he <strong>posterior distribution</strong> and is the basis for inference, a distribution, possibly multivariate if more than one parameter
(<span class="math inline">\(\theta\)</span>). <span class="math inline">\(\frac{P(\text{data} | \theta )\)</span> is the <strong>likelihood</strong>, think back to the previous section. <span class="math inline">\(P(\text{data})\)</span> is called the <strong>prior distribution</strong> and represents what you know before seeing the data. The source of much discussion about the Bayesian approach. Now.</p>
<p><span class="math display">\[P(\text{data}) = \int P(\text{data}|\theta)P(\theta)d\theta\]</span>
is typically a high-dimensional integral, difficult if not impossible to calculate.</p>
<p><strong>A simple example:</strong> lobsters</p>
<p>Again we consider data from the published article <a href="https://www.sciencedirect.com/science/article/pii/S0022098115000039">Influence of predator identity on the strength of predator avoidance responses in lobsters.</a>.</p>
<p>Recall that the authors were interested in how a juvenile lobster’s size was related to its vulnerability to predation. In total, 159 juvenile lobsters were collected from their natural habitat in the Gulf of Maine, USA, and the length of each lobster’s carapace (upper shell) was measured to the nearest 3 mm. The lobsters were then tethered to the ocean floor for 24 hours. Any missing lobsters were assumed to have been consumed by a predator, while the surviving lobsters were released.</p>
<p>We define large juvenile’s as those with carapace <span class="math inline">\(\geq\)</span> 40 mm, and otherwise we class them as small.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" title="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb163-2" title="2">data &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/lobster.csv&quot;</span>)</a>
<a class="sourceLine" id="cb163-3" title="3">lobsters &lt;-<span class="st"> </span>data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb163-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">size =</span> <span class="kw">ifelse</span>(size <span class="op">&gt;=</span><span class="st"> </span><span class="dv">40</span>, <span class="st">&quot;large&quot;</span>, <span class="st">&quot;small&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb163-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">survived =</span> <span class="kw">ifelse</span>(survived <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="st">&quot;consumed&quot;</span>, <span class="st">&quot;alive&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb163-6" title="6"><span class="st">  </span><span class="kw">group_by</span>(size, survived) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb163-7" title="7"><span class="st">  </span><span class="kw">tally</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb163-8" title="8"><span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> <span class="kw">c</span>(survived), <span class="dt">values_from =</span> n)</a></code></pre></div>
<table>
<thead>
<tr>
<th style="text-align:left;">
size
</th>
<th style="text-align:right;">
alive
</th>
<th style="text-align:right;">
consumed
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
large
</td>
<td style="text-align:right;">
56
</td>
<td style="text-align:right;">
23
</td>
</tr>
<tr>
<td style="text-align:left;">
small
</td>
<td style="text-align:right;">
23
</td>
<td style="text-align:right;">
57
</td>
</tr>
</tbody>
</table>
<p>So, as before, 23 of the small juvenile lobsters survived predation from a total of 80. We are interested in the probability of survival, <span class="math inline">\(\theta\)</span>, for the general population of small lobsters. The obvious estimate is simply to take the ratio, <span class="math inline">\(\frac{23}{80} = 0.2875\)</span> . But, what are the implied stats behind our <em>common sense</em> estimate?</p>
<p>Let <span class="math inline">\(S\)</span> be the number alive after the 24 hours, then we can assume a Binomial distribution:</p>
<p><span class="math display">\[P(S = s) = {n \choose s} \theta^s (1 - \theta)^{n-s}\]</span></p>
<p>A frequentist approach would be to maximise the likelihood with respect to <span class="math inline">\(\theta\)</span>, see the previous section. This would result in the maximum likelihood estimate (MLE) of <span class="math inline">\(\hat{\theta} = \frac{23}{80} = 0.2875\)</span></p>
<p>Using a Bayesian approach we first need to start off with a prior distribution. This should reflect our <em>prior</em> beliefs about the parameter(s) of interest. We know <span class="math inline">\(\theta\)</span> is a probability, so it is a continuous random variable and that lies between zero and one.</p>
<p>A suitable prior distribution might be the Beta defined on the interval [0, 1]. Therefore, we assume <em>a priori</em> <span class="math inline">\(\theta \sim \text{Beta(a, b)}\)</span> so that <span class="math inline">\(P(\theta) = \theta^{a−1}(1 − \theta)^{b−1}\)</span>. See the plot below for the range of shapes a Beta distribution takes with different parameter values.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<p>Recall from above that</p>
<p><span class="math display">\[P(\theta∣\text{data}) = \frac{P(\text{data} | \theta )P(\theta)}{P(\text{data})},\]</span>
which can be written as</p>
<p><span class="math display">\[P(\theta∣\text{data}) \propto P(\text{data} | \theta )P(\theta).\]</span>
The <span class="math inline">\(\propto\)</span> means <em>proportional to</em>; basically this means we can ignore any terms not containing the parameters. Therefore,</p>
<p><span class="math display">\[\begin{array}{rl}
 P(\theta∣s)  &amp; \propto {n \choose s} \theta^s (1 - \theta)^{n-s}\theta^{a−1}(1 − \theta)^{b-1} \\
   &amp; \propto  \theta^{(a+s)−1}(1 − \theta)^{(b+n−s)−1}
 \end{array}.\]</span></p>
<p>So the posterior distribution for survival is <span class="math inline">\(\theta | s \sim \text{Beta}(a + s, b + n - s).\)</span></p>
<p>We’re going to choose an <strong>uninformative prior</strong> (i.e., <span class="math inline">\(\text{Beta}(1, 1)\)</span> above). So <span class="math inline">\(\theta_{\text{small}} \sim \text{Beta}(1 + 23, 1 + 80 - 23) = \text{Beta}(24, 58).\)</span> We want the expected value of this, which already has an explicit form:</p>
<p><span class="math display">\[\mathbb{E}[\text{Beta}(a, b)] = \frac{a}{a + b} = \frac{24}{82}.\]</span></p>
<p>How does this compare to our MLE estimate from above?</p>
<blockquote>
Typically, Bayesian and frequentist estimates will always agree if there is sufficient data, so long as the likelihood is not explicitly ruled out by the prior.
<footer>
— Olivier Gimenez, Bayesian statistics with R
</footer>
</blockquote>
<p><img src="_main_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<div id="prior-sensitivity" class="section level4">
<h4>Prior sensitivity</h4>
<p>When choosing a prior distribution you should focus on what that prior means in the context of the research problem. Prior choice will influence the posterior distribution. Uninformative priors can be chosen if we wish to rely only on the likelihood (i.e., let the data speak for itself), which is itself subjective based on how/where data were collected. However, uninformative priors are in general unrealistic as equal weight is given to all values!</p>
<p>Prior choice and sensitivity is beyond the scope of this course; however, I would strongly encourage you to read the linked materials at the start of this module.</p>
<p>What would happen to our posterior distribution, above, if we were to choose a different prior?</p>
<p><img src="_main_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>

</div>
</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="example-for-a-continuous-random-variable.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="module-5.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
