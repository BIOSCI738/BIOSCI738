## Modelling experimental data

### A completely randomised design (CRD) as a linear model

As we've seen in the previous module that we can write a linear model with a single explanatory variable as 

$$Y_i = \alpha + \beta_1x_i + \epsilon_i$$

When dealing with factor variables we use dummy variables and can write the above as
 
 
 $$Y_{ik} = \alpha + \tau_k + \epsilon_{ik}$$ where $\tau_k$ is called an *effect* and represents the difference between the overall average, $\alpha$, and the average at the $k_{th}$ treatment level. The errors $\epsilon_{ik}$ are again assumed to be normally distributed and independent due to the randomisation (i.e., $\epsilon_{ik} \sim N(0, \sigma^2)$.


Or you might think of the model as

$$Y_{ik} = \mu_k + \epsilon_{ik}$$

where $Y_{ik}$ is the response (i.e., observed coffee opacity) for the $i^{th}$ experimental unit (i.e., coffee cup) subjected to the $k^{th}$ level of the treatment factor (i.e., coffee type).  Here $\mu_k$ are the different (cell) means for each level of the treatment factor. See below for an illustration of this for three factor treatment levels (as in the coffee example above).

```{r, echo = FALSE, fig.height=5}
require(tidyverse)
ggplot(data.frame(x = c(-4, 17)), aes(x)) + 
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +
  stat_function(fun = dnorm, args = list(mean = 5, sd = 1))+
  stat_function(fun = dnorm, args = list(mean = 12, sd = 1)) +
  theme_classic() +
  scale_x_continuous(breaks = c(0, 5, 12), labels = c(expression(mu[1]), expression(mu[2]), expression(mu[3]))) +
  xlab("") + ylab("") + theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```



### Analysis of a CRD in `R`

Let us again consider the data containing logAUC for 12 rats subjected to three different treatments (`Surgery`), `C`, `P`, and `S` we saw in module 2.

```{r, message = FALSE, echo = FALSE}
require(tidyverse)
rats <- read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/crd_rats_data.csv")
rats$Surgery <- as_factor(rats$Surgery)
kableExtra::kable(rats) %>%
  kableExtra::kable_classic(full_width = FALSE, html_font = "Cambria")
```


**Using `aov()`** (as we did in module 2)

```{r aov}
rats_aov <- aov(logAUC ~ Surgery, data = rats)
summary(rats_aov)
```

```{r lm-quiet, echo = FALSE}
rats_lm <- lm(logAUC ~ Surgery, data = rats)
```

Hypothesis: We test the Null hypothesis, $H_0$, population (`Surgery`) means are the same on average verses the alternative hypothesis, $H_1$, that **at least one** differs from the others!

Probability of getting an **F-statistic** at least as extreme as the one we observe (think of the area under the tails of the curve below) **p-value** Pr(>F)= `r round(anova(rats_lm)$"Pr(>F)"[1],4)` tells us we have sufficient evidence to reject $H_0$ at the 1% level of significance


### Using `lm()`

```{r lm}
rats_lm <- lm(logAUC ~ Surgery, data = rats)
summary(rats_lm)$coef
```


So, which pairs of means are different? To carry out a pair-wise comparisons of means we can use two-sample t-tests, calculating our **observed**  t-value where
$\text{t-value} = \frac{\text{Sample Difference}_{ij} - \text{Difference assuming } H_0 \text{ is true}_{ij}}{\text{SE of } \text{Sample Difference}_{ij}}$. Here, $\text{Sample Difference}_{ij}$ = Difference between pair of sample means. We can then compute the p-value for observed t-value.

The output above has already done this for us:

(Intercept) = $\text{mean}_C$ = `r summary(rats_lm)$coef[1,1]`

SE of (Intercept) = SE of $\text{mean}_C$ = SEM = `r summary(rats_lm)$coef[1,2]`

$\text{Surgery}_P$ = $\text{mean}_P$ – $\text{mean}_C$ = `r summary(rats_lm)$coef[2,1]`

SE of $\text{Surgery}_P$ = SE of ($\text{mean}_P$ - $\text{mean}_C$ ) = SED = `r summary(rats_lm)$coef[2,2]`

```{r, echo = FALSE}
means$base <- summary(rats_lm)$coef[1,1]
ggplot(rats, aes(x = Surgery, y = logAUC)) + 
    geom_violin()  + 
  ylab("logAUC") +
  xlab("Treatment") +
  geom_point(data = means, aes(x = Surgery, y = avg, color = Surgery), size = 2) +
  geom_text(data = means, aes(x = Surgery, y = avg + 0.25, color = Surgery, label = paste0("Treatment mean = ",round(avg,3)))) +
  geom_hline(data = means, aes(yintercept = avg, color = Surgery), alpha = 0.3, lty = 2) +
  geom_segment(data = means[2:3,], aes(x = Surgery, y = avg, xend = Surgery, yend = base,color = Surgery), size = 1) +
  geom_text(data = means[2:3,], aes(x = Surgery, y = base - 0.25, color = Surgery, label = paste0("diff to baseline = ",round(avg - base,3)))) +
  geom_hline(data = means[1,], aes(yintercept = avg, color = Surgery)) +
  geom_text(data = means[1,],aes(x = Surgery, y = base - 0.25, color = Surgery, label = paste0("Baseline = ",round(avg,3))))
  
```


**Hypotheses being tested**

+ The t value and Pr (>|t|) are the t - and p-value for testing the null hypotheses:
	+ Mean abundance is zero for C population
	+ No difference between the population means of P and C
	+ No difference between the population means of S and C

We're interested in 2 and 3, but not necessarily 1!

 Two-sample t -tests for pairwise comparisons of means
 
+ SurgeryP : t value = Estimate ÷ Std.Error =  0.8446; Pr (>|t|) =  0.4202

**F-test:**

```{r lmsum2}
anova(rats_lm)
```
	
**The same as `aov()`** in fact `aov()` is calling `lm()` in the background.

#### Diagnostic plots

Carrying out any linear regression recall that we have some **key assumptions**

+ **Independence** 
+ There is a **linear relationship** between the response and the explanatory variables
+ The residuals have **constant variance**
+ The **residuals** are normally distributed

```{r,echo = FALSE}
options(warn=-1)
```

```{r qqnorm, warning=FALSE, message=FALSE}
gglm::gglm(rats_lm) # Plot the four main diagnostic plots
```

What do you think? Look back at module 2.

### A Factorial experiment (as a CRD)

<p align="center">![](https://magoosh.com/statistics/files/2018/04/297r7s.jpg){width=30%}</p>


#### Equal replications (balanced design)

**Data** Global metabolic profiling and comparison of relative abundances of proteins (`logAUC`) in the inner and outer left ventricle (`innerLV` and `outerLV`) wall of diabetic and healthy male Wistar rats.


```{r, echo = FALSE, message = FALSE}
require(tidyverse)
factorial <-  read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/factorial_expt.csv")
factorial %>%
  dplyr::select(c(Disease, Organ)) %>%
  group_by(Disease, Organ) %>%
  tally() %>%
  mutate(n = paste("n =", n)) %>%
  pivot_wider(names_from = Disease, values_from = n) %>%
  kableExtra::kable(.) %>%
  kableExtra::kable_classic(full_width = FALSE, html_font = "Cambria")
kableExtra::kable(factorial) %>%
  kableExtra::kable_classic(full_width = FALSE, html_font = "Cambria")
```

**Fitting models with interactions using `lm()`**

```{r}
## change to factors (saves errors with predictmeans)
factorial$Disease <- as.factor(factorial$Disease)
factorial$Organ <- as.factor(factorial$Organ)
fac_lm <- lm(logAUC ~ Disease*Organ, data = factorial)
summary(fac_lm)$coefficients
```

So, the full model is

```{r, echo = FALSE, results='asis'}
equatiomatic::extract_eq(fac_lm, wrap = TRUE, use_coefs = TRUE)
```

The three **gobal** null hypotheses being tested are

  1. $H_0: \hat{\mu}_{\text{Diabetic}} = \hat{\mu}_{\text{Healthy}}$
  2. $H_0: \hat{\mu}_{\text{innerLV}} = \hat{\mu}_{\text{outerLV}}$
  3. $H_0: \hat{\mu}_{\text{Diabetic,innerLV}} = \hat{\mu}_{\text{Diabetic,outerLV}} = \hat{\mu}_{\text{Healthy,innerLV}} = \hat{\mu}_{\text{Healthy,outerLV}}$

```{r}
anova(fac_lm)
```


What conclusions do you draw?

**Note** with a balanced design ordering of term doesn't matter. For example,

```{r}
fac_lm <- lm(logAUC ~ Disease*Organ, data = factorial)
anova(fac_lm)
fac_lm_2 <- lm(logAUC ~ Organ*Disease, data = factorial)
anova(fac_lm_2)
``` 

### Unqual replications (unbalanced design)

Here, we consider a subset of the data above.

```{r, message = FALSE, echo = FALSE}
unbalanced <- factorial 
unbalanced$logAUC[c(1:3,10)] <- NA
unbalanced_nafree <- unbalanced %>% drop_na()
unbalanced_nafree %>%
	dplyr::select(c(Disease, Organ)) %>%
  group_by(Disease, Organ) %>%
  tally() %>%
  mutate(n = paste("n =", n)) %>%
  pivot_wider(names_from = Disease, values_from = n) %>%
  kableExtra::kable(.) %>%
  kableExtra::kable_classic(full_width = FALSE, html_font = "Cambria")
kableExtra::kable(unbalanced_nafree) %>%
  kableExtra::kable_classic(full_width = FALSE, html_font = "Cambria")
```

**Fitting models with interactions using `lm()`**

**Note**: order matters. For example,

```{r}
fac_lm <- lm(logAUC ~ Disease*Organ, data = unbalanced_nafree)
anova(fac_lm)
fac_lm_2 <- lm(logAUC ~ Organ*Disease, data = unbalanced_nafree)
anova(fac_lm_2)
```

The three **global** null hypotheses being tested are the same

  1. $H_0: \hat{\mu}_{\text{Diabetic}} = \hat{\mu}_{\text{Healthy}}$
  2. $H_0: \hat{\mu}_{\text{innerLV}} = \hat{\mu}_{\text{outerLV}}$
  3. $H_0: \hat{\mu}_{\text{Diabetic,innerLV}} = \hat{\mu}_{\text{Diabetic,outerLV}} = \hat{\mu}_{\text{Healthy,innerLV}} = \hat{\mu}_{\text{Healthy,outerLV}}$
  
However, now the **order the terms affects** the estimation. Why?
