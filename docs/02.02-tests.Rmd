## Hypothesis testing: key terms 

### `r emo::ji('scream')` p-values `r emo::ji('scream')`

> "Good statistical practice, as an essential component of good scientific practice, emphasizes principles of good study design and conduct, a variety of numerical and graphical summaries of data, understanding of the phenomenon under study, interpretation of results in context, complete reporting and proper logical and quantitative understanding of what data summaries mean. No single index should substitute for scientific reasoning." `r tufte::quote_footer('--- ASA Statement on p-Values')`

In experimental situations a **large tail proportion** (large p-value) means that the luck of the randomisation quite often produces test statistics **as large** or **even larger** than what we've got in our data.
  
A **small tail proportion** (small p-value) means that the luck of the randomisation draw **hardly ever produces** test statistics as large as we've got in our data.

**What is a p-Value?**

Informally, a p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value.

**P-values** can indicate how incompatible the data are with a specified statistical model, but they **do not** measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Scientific conclusions and business or policy decisions **should not** be based only on whether a p-value passes a specific threshold. A p-value, or statistical significance, does **not** measure the size of an effect or the importance of a result. **Statistical significance does not imply practical significance.** **Statistical significance says nothing about the size of treatment differences.** By itself, a p-value does **not** provide a good measure of evidence regarding a model or hypothesis


### Type I and Type II errors

> "Type I Zoom error: you think people can hear you, but youâ€™re actually on mute.  Type II Zoom error: you think your muted, but actually people can hear you." `r tufte::quote_footer('--- @CynPeacock, Twitter')`


#### Type I

A **Type I** error (false positive): declare a difference (i.e., reject $H_0$) when there is no difference (i.e. $H_0$ is true). Risk of the Type I error is determined by the *level of significance* (which we set!) (i.e., $\alpha =\text{ P(Type I error)} = \text{P(false positive)}$.

<p align="center">![](https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/type_1_errors.png)</p>


#### Type II

A **Type II** error (false negative): difference not declared (i.e., $H_0$ not rejected) when there is a difference (i.e., $H_0$ is false). Let $\beta =$ P(do not reject $H_0$ when $H_0$ is false); so, $1-\beta$ = P(reject $H_0$ when $H_0$ is false) = P(a true positive), which is the statistical **power** of the test.

<p align="center">![](https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/type_2_errors.png)</p>

#### Family-Wise Error Rate (FWER)

**Each** time we carry out a hypothesis test the probability we get a false positive result (type I error) is given by $\alpha$ (the *level of significance* we choose).

When we have **multiple comparisons** to make we should then control the **Type I** error rate across the entire *family* of tests under consideration, i.e., control the **Family-Wise Error Rate (FWER)**; this ensures that the risk of making at least one **Type I** error among the family of comparisons in the experiment is $\alpha$. More on this in later chapters.


|State of Nature  | Don't reject $H_0$ | reject $H_0$ |
|---              |---                |---            |
| $H_0$ is true |  `r emo::ji("check")` | Type I error  |
| $H_0$ is false  | Type II error  | `r emo::ji("check")` |

<p align="center">![](https://miro.medium.com/max/924/0*8P474MYDyFZZBdVQ.png)</p>

## Parametric hypothesis tests

Recall, the P$\overline{\text{a}}$ua dataset. It contains the following variables

 + `Age` of  P$\overline{\text{a}}$ua in years (calculated from counting rings in the cone) 
 + `Length` of  P$\overline{\text{a}}$ua shell in centimeters
 + `Species` of  P$\overline{\text{a}}$ua: *Haliotis iris* (typically found in NZ) and
*Haliotis australis* (less commonly found in NZ) 

```{r, echo = TRUE, message = FALSE}
library(tidyverse)
paua <- read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/paua.csv")
```

```{r}
glimpse(paua)
```

### One-Sample t-test

Using a violin plot we can look at the distribution of shell `Length`. We can calculate the average `Length` of all shells in our sample

```{r}
paua %>% summarise(average_length = mean(Length))
```


```{r vio1, echo = FALSE}
## violin plot with transparent points
os <- ggplot(paua,aes(x = 1,y = Length)) + 
  geom_violin() +
  geom_jitter(alpha = 0.4) +
  ylab("Shell length (cms)") + xlab("") +
  theme_linedraw() +
  geom_point(aes(x = 1, y = mean(Length)), size = 2) +
  geom_hline(aes( yintercept = mean(Length)), lty = 2, alpha = 0.5,
             col = "brown", size = 2) +
  theme(legend.position = "none") +
  geom_text(aes(x = 1, y = mean(Length) + 0.5, 
                label = paste0("Averege = ",round(mean(Length),3), "cm")),
            col = "brown", size = 5) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
os
  
```

What about drawing inference? Do we believe that the average length of P$\overline{\text{a}}$ua shells is, say, 5cm? We know our sample average, but can we make any claims based on this one number?

How do we reflect our uncertainty about the population mean? **Remember, it's the population we want to make inference on based on our sample!** 

Enter the Standard Error of the Mean (SEM),  $$\text{SEM} = \frac{\sigma}{\sqrt{n}}, $$ where $\sigma = \sqrt{\frac{\Sigma_{i = 1}^n(x_i - \bar{x})^2}{n-1}}$ ($i = 1,...,n$) is the standard deviation (SD) of the sample, $n$ is the sample size, and $\bar{x}$ is the sample mean.


**Calculating $\Sigma_{i = 1}^n(x_i - \bar{x})^2, i = 1,...,n$ by hand**.

In, relatively, plain English this sum is the sum squared differences of the distances between the $i^{th}$ observation and the sample mean $\bar{x}$ (denoted $\mu_x$ in the GIF below)

<p align="center>![](https://raw.githubusercontent.com/cmjt/statbiscuits/master/figs_n_gifs/var.gif)</p>

So using the example values in the GIF

```{r}
## our sample of values
x <- c(1,2,3,5,6,9)
## sample mean
sample_mean <- mean(x)
sample_mean
## distance from mean for each value
distance_from_mean <- x - sample_mean
distance_from_mean
## squared distance from mean for each value
squared_distance_from_mean <- distance_from_mean^2
squared_distance_from_mean
## sum of the squared distances
sum(squared_distance_from_mean)
```

**Calculating SD and SEM**

Now what about the **SD**? Remember it's the $\sqrt{\frac{\Sigma_{i = 1}^n(x_i - \bar{x})^2}{n-1}}$ so = $\sqrt{\frac{`r sum(squared_distance_from_mean)`}{n-1}}$ = $\sqrt{\frac{`r sum(squared_distance_from_mean)`}{`r length(x)`-1}}$ = $\sqrt{\frac{`r sum(squared_distance_from_mean)`}{`r length(x)-1`}}$ = `r sqrt(sum(squared_distance_from_mean)/(length(x) - 1))`.

Or we could just use `R`'s `sd()` function

```{r}
sd(x)
```
So the **SEM** is $\frac{\text{SD}}{\sqrt{n}}$ = $\frac{`r sd(x)`}{\sqrt{`r length(x)`}}$

In `R`

```{r}
sd(x)/sqrt(length(x))

```

For the `paua` data we can simply use the in-built functions in `R` to calculate the SEM

```{r sem}
sem <- paua %>% summarise(mean = mean(Length),
                   sem = sd(Length)/sqrt(length(Length)))
sem
  
```

**Visualising the uncertainty**

Recall that the SEM is a measure of uncertainty about the mean. So we can use it to express our uncertainty visually. Typically $\pm$ twice the SEM is the interval used:

```{r vizun, echo = FALSE}
os + geom_hline(data = sem, aes(yintercept = mean + 2*sem), lty = 3, alpha = 0.5, 
                col = "brown", size = 2) +
  geom_hline(data = sem, aes(yintercept = mean - 2*sem), lty = 3, alpha = 0.5,
             col = "brown", size = 2)
```

**Why error bars that are $\pm$ twice the SEM?**

This is approximately the 95% confidence interval for the population mean (*see lecture*)

The exact 95% CI is given by $\bar{x}$ (mean) $\pm$ $t_{df,1 - \alpha/2}$ $\times$ SEM

  + df = degrees of freedom (*in this situation* df = n - 1)
  + $\alpha$ = level of significance

Each mean has its own confidence interval whose width depends on the SEM for that mean

When the df (*more on these later*) are large (e.g. 30 or greater) and $\alpha$ = 0.05 $t_{df,1 - \alpha/2}$ = $t_{large,0.975}$ $\approx$ 2. Hence, the 95% confidence interval for the population mean is approximately $\bar{x}$ (mean) $\pm$ 2 $\times$ SEM

**Back to our hypothesis test**

**Question:** Do we believe that the average length of P$\overline{\text{a}}$ua shells is 5cm?

**Formalizing into a hypothesis test:**  

 + *Null hypothesis*: On average P$\overline{\text{a}}$ua shells are 5cm long
 + *Alternative hypothesis*: On average P$\overline{\text{a}}$ua shells are **not** 5cm long
 + *Notationally*: $H_0: \mu = 5$ vs $H_1: \mu \neq 5$ (*$\mu$ is the proposed mean*)
 
**Calculating a statistic** (*we use a t-statistic*)

t-statistic $= \frac{\bar{x}- \mu}{\text{SEM}}$ = $\frac{`r sem[1]` - 5}{`r sem[2]`}$ = `r round((sem[1] - 5)/sem[2], 3)`

   + $\bar{x}$ is the sample mean

   + $\mu$ is the theoretical value (*proposed mean*)
   
**The corresponding p-value**

Recall that a p-value is the probability under a specified statistical model that a statistical summary of the data would be equal to or more extreme than its observed value

So in this case it's the probability, under the null hypothesis ($\mu = 5$), that we would observe a statistic as least as extreme as we did.

Under our null hypothesis the distribution of the t-statistic is as below. The one calculated from our hypothesis test was 1.2391. Now, remember that our alternative hypotheses was $H_1: \mu \neq 5$ so we have to consider both sides of the inequality; hence, anything as least as extreme is either $> 1.2391$ or $< -1.2391$ to our observed statistic (vertical lines). Anything as least as extreme is therefore given by the grey shaded areas.

```{r, echo = FALSE}
data <- data.frame(quantiles = rt(1000,df = 59))
data$dens <- dt(data$quantiles, df = 59)
ggplot(data, aes(x = quantiles, y = dens)) +
  geom_line() +
  theme_classic() +
  ylab("density") +
  xlab("t-statistic") +
  geom_vline(xintercept = 1.2391, color = "cyan4" , size = 2) + 
  geom_vline(xintercept = -1.2391, color = "cyan4" , size = 2) +
  geom_area(data = data[data$quantiles >= 1.2391,],
            mapping = aes(x = quantiles, y = dens),fill = "grey",alpha = 0.3) +
  geom_area(data = data[data$quantiles <= -1.2391,],
            mapping = aes(x = quantiles, y = dens),fill = "grey",alpha = 0.3)

```

We can calculate the p-value using the `pt()` function (where `q` is our calculated t-statistic, and `df` are the degrees of freedom from above):

```{r}
2*(1 - pt(q  = 1.2391,df = 59))
```



Or we could do all of the above in one step using `R`

```{r ostest}
t.test(paua$Length, mu = 5 )
```

Recall, that the p-value gives the probability that under our null hypothesis we observe anything as least as extreme as what we did (hence the $\times 2$, think of the grey shaded area in the graph). This probability is $\sim$ 22%. Do you think what we've observed is likely under the null hypothesis?

Does this plot help? The proposed mean is shown by the blue horizontal line; the dashed line shows the sample mean and the dotted lines $\pm$ the SEM.

```{r vizunmu, echo  = FALSE}
os + geom_hline(data = sem, aes(yintercept = mean + 2*sem), lty = 3, alpha = 0.5,
                col = "brown", size = 2) +
  geom_hline(data = sem, aes(yintercept = mean - 2*sem), lty = 3, alpha = 0.5,
             col = "brown", size = 2) +
  geom_hline(aes(yintercept = 5), color = "blue", size = 2)
```

### Differences between two means

```{r vio, echo = FALSE}
means <- paua %>% group_by(Species) %>% summarise(means = mean(Length))
## violin plot with transparent points
a <- ggplot(paua,aes(x = Species, y = Length, col = Species)) + 
  geom_violin() +
  geom_jitter(alpha = 0.4) +
  ylab("Length (cm)") + xlab("") +
  theme_classic() +
  geom_point(data = means, aes(x = Species, y = means, color = Species), size = 2) +
  geom_hline(data = means, aes(yintercept = means, color = Species), lty = 2, alpha = 0.5) +
  theme(legend.position = "none") +
  geom_text(data = means, aes(x = Species, y = means + 0.25, label = paste0("Species averege = ",round(means,3)), color = Species))
a 
  
```

**Calculating the differences between species means:**

*Haliotis australis* average - *Haliotis iris* average = $\mu_{\text{Haliotis australis}} - \mu_{\text{Haliotis iris}}$ = `r round(means[1,2],3)` - `r round(means[2,2],3)` = `r round(means[1,2] - means[2,2],3)`. Doesn't really tell us much... 

As above the average values are all well and good, but what about **variation?** Recall the SEM from the one-sample t-test? The same idea holds here, although the calculation is a little bit more complicated (as we have to think about the number of observations in each group). But from the two group SEMs we can calculate the Standard Error of the Difference between two means, **SED**.


#### Independent samples t-test using `t.test()`

**Question:** Do we believe that on average the length of P$\overline{\text{a}}$ua shells are equal between species?

**Formalizing into a hypothesis test:**
   
   + **Null hypothesis**: On average the species' shells are the same length
   + **Alternative hypothesis**: they aren't!
   + **Notationally**: $H_0: \mu_{\text{Haliotis iris}} - \mu_{\text{Haliotis australis}} = 0$ vs $H_1: \mu_{\text{Haliotis iris}} \neq \mu_{\text{Haliotis australis}},$ where $\mu_{j}$ is the average length for species, $j =$ (*Haliotis iris*, *Haliotis australis*).

Let us now **calculate the test statistic:** t-statistic = $\frac{\bar{x}_{\text{difference}} - \mu}{\text{SED}}$ = $\frac{\bar{x}_{\text{difference}} - 0}{\text{SED}}n$ where $\bar{x}_{\text{difference}}$ is the differences between the species` averages. 

Calculations area a little bit more tricky here so let's use `R`:

```{r lmt}
test <- t.test(Length ~ Species, data = paua)
## printing out the result
test
test$p.value

```

Listed are the t-statistic, `t` = `r test$statistic` and the p-value, `p-value` = `r round(test$p.value,6)` for the hypothesis test outlined above. What would you conclude?


### One-Way Analysis of Variance (ANOVA)

What if we had more than two groups?

In this section we consider the following data of the calculated logAUC for 12 rats subjected to three different treatments (`Surgery`), `C`, `P`, and `S`: 

```{r data-quiet, message = FALSE, echo = FALSE}
library(tidyverse)
rats <- read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/crd_rats_data.csv")
rats$Surgery <- as_factor(rats$Surgery)
kableExtra::kable(rats) %>%
  kableExtra::kable_classic(full_width = FALSE, html_font = "Cambria")
```

To read the data directly into `R` you can use

```{r, eval = FALSE}
readr::read_csv("https://raw.githubusercontent.com/STATS-UOA/databunker/master/data/crd_rats_data.csv")
```

##### Between group SS (SSB)

**The idea**: Assess **distances** between treatment (*surgical condition*) means relative to our uncertainty about the actual (*true*) treatment means.


```{r, echo = FALSE}
means <- rats %>% group_by(Surgery) %>% summarise(avg = mean(logAUC))
mean <- mean(rats$logAUC)
means$ends <- mean
ggplot(rats, aes(x = Surgery, y = logAUC)) + 
    geom_violin()  + 
  ylab("logAUC") +
  xlab("Treatment") +
  geom_point(data = means, aes(x = Surgery, y = avg, color = Surgery), size = 2) +
  geom_text(data = means, aes(x = Surgery, y = avg + 0.25, color = Surgery, label = paste0("Treatment mean = ",round(avg,3)))) +
  geom_hline(data = means, aes(yintercept = avg, color = Surgery), alpha = 0.3, lty = 2) +
  geom_hline(yintercept = mean, color = "red", alpha = 0.3) +
  annotate(geom = 'text', label = paste0("Overall average = ",round(mean,3)) , 
           x = -Inf, y = Inf, hjust = 0, vjust = 1.5, color = "red") +
  geom_segment(data = means, aes(x = Surgery, y = avg, xend = Surgery, yend = ends,color = Surgery), size = 1) +
  geom_text(data = means, aes(x = Surgery, y = ends + 0.25, color = Surgery, label = paste0("diff to overall = ",round(avg - ends,3))))
  
  
```


**Add up the differences:** `r round(means$avg[1] - mean,3)` + `r round(means$avg[2] - mean,3)` + `r round(means$avg[3] - mean,3)` = `r round(sum(means$avg - mean),3)`. **This is always the case!**

**So adding up the differences:** `r round(means$avg[1] - mean,3)` + `r round(means$avg[2] - mean,3)` + `r round(means$avg[3] - mean,3)` = `r round(sum(means$avg - mean),3)`. **Not a great way to measure distances!**


**Sums of Squares?** 

`r round(means$avg[1] - mean,3)`^2 + `r round(means$avg[2] - mean,3)`^2 + `r round(means$avg[3] - mean,3)`^2

**add up the squared differences?** but... there are 4 observations in each group (treatment)


4$\times$(`r round(means$avg[1] - mean,3)`)^2 + 4$\times$(`r round(means$avg[2] - mean,3)`)^2 + 4$\times$(`r round(means$avg[3] - mean,3)`)^2

This is the **Between Groups Sums of Squares** or the **Between group SS (SSB)** 


So the Between group SS (SSB) = `r sum(4*((means$avg - mean)^2))`


**Adding up the differences:** `r round(means$avg[1] - mean,3)` + `r round(means$avg[2] - mean,3)` + `r round(means$avg[3] - mean,3)` = `r round(sum(means$avg - mean),3)`. **This is always the case** and that itself gives us information...


**We only need to know two of the values to work out the third!**

So we have only 2 bits of **unique** information; **SSB degrees of freedom** = 2

##### Within group SS (SSW)

The **Within group SS (SSW)** arises from the same idea:

To assess distances between treatment (surgical condition) means **relative** to our uncertainty about the actual (true) treatment means.

Procedure:

 + Observation - Treatment mean
 + Square the difference
 + Add them up!

**Within group SS (SSW)** *unexplained variance*

```{r,echo = FALSE}
rats_df <- rats %>% mutate(ov_avg = mean(logAUC)) %>% 
  group_by(Surgery) %>% mutate(tr_avg = mean(logAUC), tr_avg_minus_ov_avg = mean(logAUC) - ov_avg,
                               obvs_minus_tr_avg = logAUC - mean(logAUC))
jit <- ggplot() + 
  geom_jitter(data = rats, aes(x = Surgery, y = logAUC))

rats_df$x_points <- layer_data(jit)$x
rats_df$y_points <- layer_data(jit)$y

ggplot() + 
  ylab("logAUC") +
  xlab("Treatment") +
  geom_point(data = means, aes(x = Surgery, y = avg, color = Surgery), size = 2) +
  geom_text(data = means, aes(x = Surgery, y = avg + 0.25, color = Surgery, 
                              label = paste0("Treatment mean = ",round(avg,3)))) +
  geom_hline(data = means, aes(yintercept = avg, color = Surgery), alpha = 0.3, lty = 2) +
  geom_point(data = rats_df, aes(x = x_points, y = y_points, color = Surgery), alpha = 0.3) +
  geom_segment(data = rats_df, aes(x = x_points, y = y_points, 
                                   xend = x_points, yend = tr_avg,color = Surgery), 
               size = 1, alpha = 0.5) +
    theme(legend.position = "none")
```

##### F-statistic

Recall the Between group SS (**SSB**) = `r sum(4*((means$avg - mean)^2))`

So mean **SSB** =  `r sum(4*((means$avg - mean)^2))` / 2


The within group SS (**SSW**) = `r sum(rats_df$obvs_minus_tr_avg^2)`

Here we have 3$\times$ 3 bits of *unique* information: within groups **degrees of freedom** is 9.

So mean **SSW** = `r round(sum(rats_df$obvs_minus_tr_avg^2),3)`/9


Consider the ratio ${\frac{{\text{variation due to treatments}}}{{\text{unexplained variance}}}} = {\frac{{\text{ mean between-group variability}}}{{\text{mean within-group variability}}}}$  $=\frac{\text{mean SSB}}{\text{mean SSW}}$ $=\frac{\text{MSB}}{\text{MSW}}$  = $=\frac{\text{experimental variance}}{\text{error variance}}$ `r (sum(4*((means$avg - mean)^2))/2)/(sum(rats_df$obvs_minus_tr_avg^2)/9)`

This is the **F-statistic!**

##### Degrees of freedom (DF)

Essentially *statistical currency* (i.e., **unique** bits of information). So in the example above we have 3 treatment groups and if we know the mean of two we know the third (i.e., 2 *unique* bits of info) so SSB df = 2. 

Now, for SSW df We have 12 observations (4 in each group); we know the treatment means so if we have three of those observed values in each group we know the fourth: 12 - 3 = 9 (i.e., number of observations - number of df lost due to knowing the cell means).

##### Inference

Hypothesis: We test the Null hypothesis, $H_0$, population (`Surgery`) means are the same on average verses the alternative hypothesis, $H_1$, that **at least one** differs from the others!

Under our null hypothesis the distribution of the F-statistic is as below. The value calculated from our hypothesis test was  16.359. This observed test statistic is shown by the vertical line. To calculate the relevant p-value we can use

```{r}
(1 - pf(q  = 16.351,df1 = 2, df2 = 9))
```

Thus, the probability of getting an **F-statistic** at least as extreme as the one we observe (think of the area under the tails of the curve below) **p-value** Pr(>F)= `r round((1 - pf(q  = 16.351,df1 = 2, df2 = 9)),4)` tells us we have sufficient evidence to reject $H_0$ at the 1% level of significance.



```{r, echo = FALSE}
rats_aov <- aov(logAUC ~ Surgery, data = rats)
stats_df <- data.frame(Fs = summary(rats_aov)[[1]][[4]][[1]])
crit_df <- as.data.frame(apply(stats_df,2,rep,each = 100))
crit_df$Fs <- c(sapply(stats_df$Fs, function(x) seq(x,20, length.out = 100)))
crit_df$y <- df(crit_df$Fs,df1 = 2,df2 = 9) ## corresponding F val
ggplot(stats_df,aes(x = Fs)) +
  geom_vline(aes(xintercept = Fs), color = "cyan4" , size = 2) +
    geom_line(data = data.frame(x = seq(0,20,.1),
                              y  = df(seq(0,20,.1),df1 = 2,df2 = 9)),
              aes(x = x,y = y), alpha = 0.7, size = 2) +
  theme_classic() +
  ylab("density") +
  xlab("F-statistic") +
  geom_line(data = crit_df,mapping = aes(x = Fs,y = y),color = "darkred", size = 2) +
  geom_text(aes(4, 1,label = paste("F-statistic =", format(round(Fs, 2), nsmall = 2))),
              size = 4, hjust = 0, color = "cyan4")  +
  geom_text(aes(4, 0.95,label = paste("p-value =", format(round(pf(Fs,2,9,lower.tail = FALSE),4), 
                                                         nsmall = 2))),
              size = 4, hjust = 0, color = "darkred") 
  

```


Alternatively, we could do this in one step **using `aov()`:**

```{r}
summary(aov(logAUC ~ Surgery, data = rats))
```
