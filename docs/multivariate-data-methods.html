<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>12 Multivariate Data Methods | bluebook BIOSCI738</title>
  <meta name="description" content="12 Multivariate Data Methods | bluebook BIOSCI738" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="12 Multivariate Data Methods | bluebook BIOSCI738" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="12 Multivariate Data Methods | bluebook BIOSCI738" />
  
  
  

<meta name="author" content="Charlotte Jones-Todd" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="resampling-procedures.html"/>
<link rel="next" href="dimension-reduction.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="src/my-style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#course-overview"><i class="fa fa-check"></i><b>0.1</b> Course Overview</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#key-topics"><i class="fa fa-check"></i><b>0.2</b> Key Topics</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html"><i class="fa fa-check"></i><b>1</b> <code>R</code>, <code>RStudio</code>, and <code>git</code></a><ul>
<li class="chapter" data-level="1.1" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#intro-to-r-rstudio"><i class="fa fa-check"></i><b>1.2</b> Intro to <code>R</code> &amp; <code>RStudio</code></a><ul>
<li class="chapter" data-level="1.2.1" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#why"><i class="fa fa-check"></i><b>1.2.1</b> Why?</a></li>
<li class="chapter" data-level="1.2.2" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>1.2.2</b> Installing R and RStudio</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#getting-started"><i class="fa fa-check"></i><b>1.3</b> Getting started</a><ul>
<li class="chapter" data-level="1.3.1" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#r-errors"><i class="fa fa-check"></i><b>1.3.1</b> R errors 😱</a></li>
<li class="chapter" data-level="1.3.2" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#r-scripts-a-.r-file"><i class="fa fa-check"></i><b>1.3.2</b> R <em>Script</em>s (a <code>.r</code> file)</a></li>
<li class="chapter" data-level="1.3.3" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#writing-comments"><i class="fa fa-check"></i><b>1.3.3</b> Writing <em>Comments</em></a></li>
<li class="chapter" data-level="1.3.4" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#change-the-rstudio-appearance-up-to-your-taste"><i class="fa fa-check"></i><b>1.3.4</b> Change the <code>RStudio</code> appearance up to your taste</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#reproducible-research"><i class="fa fa-check"></i><b>1.4</b> Reproducible research</a><ul>
<li class="chapter" data-level="1.4.1" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#good-practice"><i class="fa fa-check"></i><b>1.4.1</b> Good practice</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#version-control-with-git-and-github"><i class="fa fa-check"></i><b>1.5</b> Version control with <code>git</code> and GitHub</a><ul>
<li class="chapter" data-level="1.5.1" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#setup-tldr"><i class="fa fa-check"></i><b>1.5.1</b> Setup TL;DR</a></li>
<li class="chapter" data-level="1.5.2" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#cloning-a-repository-from-github-using-rstudio"><i class="fa fa-check"></i><b>1.5.2</b> Cloning a repository from <code>GitHub</code> using <code>RStudio</code></a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>1.6</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="1.6.1" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#starting-out-with-tidyverse"><i class="fa fa-check"></i><b>1.6.1</b> Starting out with <code>tidyverse</code></a></li>
<li class="chapter" data-level="1.6.2" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#reading-in-data-from-a-.csv-file"><i class="fa fa-check"></i><b>1.6.2</b> Reading in data from a <code>.csv</code> file</a></li>
<li class="chapter" data-level="1.6.3" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#explore-your-data"><i class="fa fa-check"></i><b>1.6.3</b> Explore your data</a></li>
<li class="chapter" data-level="1.6.4" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#explore-your-data-1"><i class="fa fa-check"></i><b>1.6.4</b> Explore your data</a></li>
<li class="chapter" data-level="1.6.5" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#the-pipe-operator"><i class="fa fa-check"></i><b>1.6.5</b> The pipe operator <code>%&gt;%</code></a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="r-rstudio-and-git.html"><a href="r-rstudio-and-git.html#other-resources"><i class="fa fa-check"></i><b>1.7</b> Other resources</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="māori-data-sovereignty-principles.html"><a href="māori-data-sovereignty-principles.html"><i class="fa fa-check"></i><b>2</b> Māori Data Sovereignty principles</a><ul>
<li class="chapter" data-level="2.1" data-path="māori-data-sovereignty-principles.html"><a href="māori-data-sovereignty-principles.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="māori-data-sovereignty-principles.html"><a href="māori-data-sovereignty-principles.html#māori-data-sovereignty-principles-1"><i class="fa fa-check"></i><b>2.2</b> Māori Data Sovereignty principles</a></li>
<li class="chapter" data-level="2.3" data-path="māori-data-sovereignty-principles.html"><a href="māori-data-sovereignty-principles.html#māori-data-sovereignty-principles-2"><i class="fa fa-check"></i><b>2.3</b> Māori Data Sovereignty principles</a></li>
<li class="chapter" data-level="2.4" data-path="māori-data-sovereignty-principles.html"><a href="māori-data-sovereignty-principles.html#resources"><i class="fa fa-check"></i><b>2.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html"><i class="fa fa-check"></i><b>3</b> Data wrangling and vizualisation</a><ul>
<li class="chapter" data-level="3.1" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#learning-objectives-2"><i class="fa fa-check"></i><b>3.1</b> Learning objectives</a></li>
<li class="chapter" data-level="3.2" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#common-dataframe-manipulations-in-the-tidyverse"><i class="fa fa-check"></i><b>3.2</b> Common dataframe manipulations in the <code>tidyverse</code></a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#using-dplyr-and-tidyr"><i class="fa fa-check"></i><b>3.2.1</b> Using <code>dplyr</code> and <code>tidyr</code></a></li>
<li class="chapter" data-level="3.2.2" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#introuducing-the-palmer-penguins"><i class="fa fa-check"></i><b>3.2.2</b> Introuducing the <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081">Palmer penguins</a></a></li>
<li class="chapter" data-level="3.2.3" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#common-dataframe-manipulations-in-the-tidyverse-using-dplyr-and-tidyr"><i class="fa fa-check"></i><b>3.2.3</b> Common dataframe manipulations in the <code>tidyverse</code>, using <code>dplyr</code> and <code>tidyr</code></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#data-viz"><i class="fa fa-check"></i><b>3.3</b> Data Viz</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#exploratory-and-explanatory-plots"><i class="fa fa-check"></i><b>3.3.1</b> Exploratory and explanatory plots</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#ten-simple-rules-for-better-figures"><i class="fa fa-check"></i><b>3.4</b> Ten Simple Rules for Better Figures</a></li>
<li class="chapter" data-level="3.5" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#ggplot2"><i class="fa fa-check"></i><b>3.5</b> <code>ggplot2</code></a><ul>
<li class="chapter" data-level="3.5.1" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#ggplot2-layers"><i class="fa fa-check"></i><b>3.5.1</b> <code>ggplot2</code> layers</a></li>
<li class="chapter" data-level="3.5.2" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#examples"><i class="fa fa-check"></i><b>3.5.2</b> Examples</a></li>
<li class="chapter" data-level="3.5.3" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#the-good-the-bad-and-the-ugly..."><i class="fa fa-check"></i><b>3.5.3</b> The Good, the Bad, and the Ugly...</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="data-wrangling-and-vizualisation.html"><a href="data-wrangling-and-vizualisation.html#resources-1"><i class="fa fa-check"></i><b>3.6</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html"><i class="fa fa-check"></i><b>4</b> Introduction to the design and analysis of experiments</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#learning-objectives-3"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#key-phrases"><i class="fa fa-check"></i><b>4.2</b> Key phrases</a></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#three-key-principles"><i class="fa fa-check"></i><b>4.3</b> Three key principles:</a><ul>
<li class="chapter" data-level="4.3.1" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#replication"><i class="fa fa-check"></i><b>4.3.1</b> <strong>Replication</strong></a></li>
<li class="chapter" data-level="4.3.2" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#randomization"><i class="fa fa-check"></i><b>4.3.2</b> <strong>Randomization</strong></a></li>
<li class="chapter" data-level="4.3.3" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#blocking"><i class="fa fa-check"></i><b>4.3.3</b> <strong>Blocking</strong></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#one-way-analysis-of-variance-anova"><i class="fa fa-check"></i><b>4.4</b> One-Way <strong>An</strong>alysis <strong>o</strong>f <strong>Va</strong>riance (ANOVA)</a><ul>
<li class="chapter" data-level="4.4.1" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#between-group-ss-ssb"><i class="fa fa-check"></i><b>4.4.1</b> Between group SS (SSB)</a></li>
<li class="chapter" data-level="4.4.2" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#within-group-ss-ssw"><i class="fa fa-check"></i><b>4.4.2</b> Within group SS (SSW)</a></li>
<li class="chapter" data-level="4.4.3" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#f-statistic"><i class="fa fa-check"></i><b>4.4.3</b> F-statistic</a></li>
<li class="chapter" data-level="4.4.4" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#degrees-of-freedom-df"><i class="fa fa-check"></i><b>4.4.4</b> Degrees of freedom (DF)</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#p-values"><i class="fa fa-check"></i><b>4.5</b> 😱 p-values 😱</a></li>
<li class="chapter" data-level="4.6" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#terminology-and-issues"><i class="fa fa-check"></i><b>4.6</b> Terminology and issues</a></li>
<li class="chapter" data-level="4.7" data-path="introduction-to-the-design-and-analysis-of-experiments.html"><a href="introduction-to-the-design-and-analysis-of-experiments.html#resources-2"><i class="fa fa-check"></i><b>4.7</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="a-completely-randomomised-design.html"><a href="a-completely-randomomised-design.html"><i class="fa fa-check"></i><b>5</b> A completely randomomised design</a><ul>
<li class="chapter" data-level="5.1" data-path="a-completely-randomomised-design.html"><a href="a-completely-randomomised-design.html#learning-objectives-4"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="a-completely-randomomised-design.html"><a href="a-completely-randomomised-design.html#analysis-of-a-completely-randomised-design-in-r-aov-and-lm"><i class="fa fa-check"></i><b>5.2</b> Analysis of a Completely Randomised Design in <code>R</code>: <code>aov()</code> and <code>lm()</code></a><ul>
<li class="chapter" data-level="5.2.1" data-path="a-completely-randomomised-design.html"><a href="a-completely-randomomised-design.html#aov"><i class="fa fa-check"></i><b>5.2.1</b> <code>aov()</code></a></li>
<li class="chapter" data-level="5.2.2" data-path="a-completely-randomomised-design.html"><a href="a-completely-randomomised-design.html#lm"><i class="fa fa-check"></i><b>5.2.2</b> <code>lm()</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html"><i class="fa fa-check"></i><b>6</b> Multiple comparisons</a><ul>
<li class="chapter" data-level="6.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#learning-objectives-5"><i class="fa fa-check"></i><b>6.1</b> Learning objectives</a></li>
<li class="chapter" data-level="6.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#adjustments-for-multiple-testing"><i class="fa fa-check"></i><b>6.2</b> Adjustments for multiple testing</a><ul>
<li class="chapter" data-level="6.2.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#classification-of-multiple-hypothesis-tests"><i class="fa fa-check"></i><b>6.2.1</b> Classification of multiple hypothesis tests</a></li>
<li class="chapter" data-level="6.2.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#using-the-predictmeans-package"><i class="fa fa-check"></i><b>6.2.2</b> Using the <code>predictmeans</code> package</a></li>
<li class="chapter" data-level="6.2.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#multiple-comparison-procedures"><i class="fa fa-check"></i><b>6.2.3</b> Multiple comparison procedures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="factorial-experiments.html"><a href="factorial-experiments.html"><i class="fa fa-check"></i><b>7</b> Factorial experiments</a><ul>
<li class="chapter" data-level="7.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#learning-objectives-6"><i class="fa fa-check"></i><b>7.1</b> Learning objectives</a></li>
<li class="chapter" data-level="7.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#factorial-design-as-a-crd"><i class="fa fa-check"></i><b>7.2</b> Factorial design (as a CRD)</a><ul>
<li class="chapter" data-level="7.2.1" data-path="factorial-experiments.html"><a href="factorial-experiments.html#equal-replications-balanced-design"><i class="fa fa-check"></i><b>7.2.1</b> Equal replications (balanced design)</a></li>
<li class="chapter" data-level="7.2.2" data-path="factorial-experiments.html"><a href="factorial-experiments.html#unqual-replications-unbalanced-design"><i class="fa fa-check"></i><b>7.2.2</b> Unqual replications (unbalanced design)</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="factorial-experiments.html"><a href="factorial-experiments.html#tldr-model-formula-syntax-in-r"><i class="fa fa-check"></i><b>7.3</b> TL;DR, Model formula syntax in <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="blocking-incorporating-into-design-and-analysis-of.html"><a href="blocking-incorporating-into-design-and-analysis-of.html"><i class="fa fa-check"></i><b>8</b> Blocking: incorporating into design and analysis of</a><ul>
<li class="chapter" data-level="8.1" data-path="blocking-incorporating-into-design-and-analysis-of.html"><a href="blocking-incorporating-into-design-and-analysis-of.html#learning-objectives-7"><i class="fa fa-check"></i><b>8.1</b> Learning objectives</a></li>
<li class="chapter" data-level="8.2" data-path="blocking-incorporating-into-design-and-analysis-of.html"><a href="blocking-incorporating-into-design-and-analysis-of.html#blocking-1"><i class="fa fa-check"></i><b>8.2</b> Blocking</a></li>
<li class="chapter" data-level="8.3" data-path="blocking-incorporating-into-design-and-analysis-of.html"><a href="blocking-incorporating-into-design-and-analysis-of.html#a-randomised-controlled-block-design-rcbd"><i class="fa fa-check"></i><b>8.3</b> A Randomised Controlled Block Design (RCBD)</a></li>
<li class="chapter" data-level="8.4" data-path="blocking-incorporating-into-design-and-analysis-of.html"><a href="blocking-incorporating-into-design-and-analysis-of.html#fixed-or-random"><i class="fa fa-check"></i><b>8.4</b> Fixed or Random???</a><ul>
<li class="chapter" data-level="8.4.1" data-path="blocking-incorporating-into-design-and-analysis-of.html"><a href="blocking-incorporating-into-design-and-analysis-of.html#ignoring-an-effect"><i class="fa fa-check"></i><b>8.4.1</b> Ignoring an effect</a></li>
<li class="chapter" data-level="8.4.2" data-path="blocking-incorporating-into-design-and-analysis-of.html"><a href="blocking-incorporating-into-design-and-analysis-of.html#analysis-using-lmer-from-lme4"><i class="fa fa-check"></i><b>8.4.2</b> Analysis using <code>lmer()</code> from <code>lme4</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html"><i class="fa fa-check"></i><b>9</b> Split-plot and repeated measures designs</a><ul>
<li class="chapter" data-level="9.1" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#learning-objectives-8"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#analysis-of-a-split-plot-design"><i class="fa fa-check"></i><b>9.2</b> Analysis of a split-plot design</a><ul>
<li class="chapter" data-level="9.2.1" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#using-aov"><i class="fa fa-check"></i><b>9.2.1</b> Using <code>aov()</code></a></li>
<li class="chapter" data-level="9.2.2" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#using-lmer-from-lmetest-and-lmer4-and-predictmeans"><i class="fa fa-check"></i><b>9.2.2</b> Using <code>lmer()</code> (from <code>lmeTest</code> and <code>lmer4</code>) and <code>predictmeans()</code></a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#analysis-of-a-repeated-measures-design"><i class="fa fa-check"></i><b>9.3</b> Analysis of a repeated measures design</a><ul>
<li class="chapter" data-level="9.3.1" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#the-data"><i class="fa fa-check"></i><b>9.3.1</b> The data</a></li>
<li class="chapter" data-level="9.3.2" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#visualise"><i class="fa fa-check"></i><b>9.3.2</b> Visualise</a></li>
<li class="chapter" data-level="9.3.3" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#using-aov-1"><i class="fa fa-check"></i><b>9.3.3</b> Using <code>aov()</code></a></li>
<li class="chapter" data-level="9.3.4" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#using-lmer-from-lmertest-and-lme4-and-predictmeans"><i class="fa fa-check"></i><b>9.3.4</b> Using <code>lmer()</code> (from <code>lmerTest</code> and <code>lme4</code>) and <code>predictmeans()</code></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="split-plot-and-repeated-measures-designs.html"><a href="split-plot-and-repeated-measures-designs.html#repeated-measures-designs-as-split-plots-in-time"><i class="fa fa-check"></i><b>9.4</b> Repeated measures designs as <em>split-plots in time</em></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="statistical-inference.html"><a href="statistical-inference.html"><i class="fa fa-check"></i><b>10</b> Statistical Inference</a><ul>
<li class="chapter" data-level="10.1" data-path="statistical-inference.html"><a href="statistical-inference.html#learning-objectives-9"><i class="fa fa-check"></i><b>10.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="statistical-inference.html"><a href="statistical-inference.html#regression"><i class="fa fa-check"></i><b>10.2</b> Regression</a><ul>
<li class="chapter" data-level="10.2.1" data-path="statistical-inference.html"><a href="statistical-inference.html#some-mathematical-notation"><i class="fa fa-check"></i><b>10.2.1</b> Some mathematical notation</a></li>
<li class="chapter" data-level="10.2.2" data-path="statistical-inference.html"><a href="statistical-inference.html#modeling-bill-depth"><i class="fa fa-check"></i><b>10.2.2</b> Modeling Bill Depth</a></li>
<li class="chapter" data-level="10.2.3" data-path="statistical-inference.html"><a href="statistical-inference.html#single-continuous-variable"><i class="fa fa-check"></i><b>10.2.3</b> Single continuous variable</a></li>
<li class="chapter" data-level="10.2.4" data-path="statistical-inference.html"><a href="statistical-inference.html#factor-and-a-continous-variable"><i class="fa fa-check"></i><b>10.2.4</b> Factor and a continous variable</a></li>
<li class="chapter" data-level="10.2.5" data-path="statistical-inference.html"><a href="statistical-inference.html#interactions"><i class="fa fa-check"></i><b>10.2.5</b> Interactions</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="statistical-inference.html"><a href="statistical-inference.html#model-comparison-selection-and-checking-again"><i class="fa fa-check"></i><b>10.3</b> Model, comparison, selection, and checking (again)</a><ul>
<li class="chapter" data-level="10.3.1" data-path="statistical-inference.html"><a href="statistical-inference.html#model-comparison-and-selection"><i class="fa fa-check"></i><b>10.3.1</b> Model comparison and selection</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="statistical-inference.html"><a href="statistical-inference.html#point-predictions-and-confidence-intervals"><i class="fa fa-check"></i><b>10.4</b> Point predictions and confidence intervals</a><ul>
<li class="chapter" data-level="10.4.1" data-path="statistical-inference.html"><a href="statistical-inference.html#confidence-intervals-for-parameters"><i class="fa fa-check"></i><b>10.4.1</b> Confidence intervals for parameters</a></li>
<li class="chapter" data-level="10.4.2" data-path="statistical-inference.html"><a href="statistical-inference.html#point-prediction"><i class="fa fa-check"></i><b>10.4.2</b> Point prediction</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="statistical-inference.html"><a href="statistical-inference.html#tldr-lm"><i class="fa fa-check"></i><b>10.5</b> TL;DR <code>lm()</code></a><ul>
<li class="chapter" data-level="10.5.1" data-path="statistical-inference.html"><a href="statistical-inference.html#model-formula-syntax"><i class="fa fa-check"></i><b>10.5.1</b> <strong>Model formula</strong> syntax</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="statistical-inference.html"><a href="statistical-inference.html#other-resources-optional-but-recommended"><i class="fa fa-check"></i><b>10.6</b> Other resources: optional but recommended</a></li>
<li class="chapter" data-level="10.7" data-path="statistical-inference.html"><a href="statistical-inference.html#beyond-linear-models-to-generalised-linear-models-glms-not-examinable"><i class="fa fa-check"></i><b>10.7</b> Beyond Linear Models to Generalised Linear Models (GLMs) (<em>not examinable</em>)</a><ul>
<li class="chapter" data-level="10.7.1" data-path="statistical-inference.html"><a href="statistical-inference.html#counting-animals..."><i class="fa fa-check"></i><b>10.7.1</b> Counting animals...</a></li>
<li class="chapter" data-level="10.7.2" data-path="statistical-inference.html"><a href="statistical-inference.html#other-modelling-approaches-not-examinable"><i class="fa fa-check"></i><b>10.7.2</b> Other modelling approaches (not examinable)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="resampling-procedures.html"><a href="resampling-procedures.html"><i class="fa fa-check"></i><b>11</b> Resampling Procedures</a><ul>
<li class="chapter" data-level="11.1" data-path="resampling-procedures.html"><a href="resampling-procedures.html#learning-objectives-10"><i class="fa fa-check"></i><b>11.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="11.2" data-path="resampling-procedures.html"><a href="resampling-procedures.html#resampling"><i class="fa fa-check"></i><b>11.2</b> Resampling</a><ul>
<li class="chapter" data-level="11.2.1" data-path="resampling-procedures.html"><a href="resampling-procedures.html#significance-tests"><i class="fa fa-check"></i><b>11.2.1</b> Significance tests</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="resampling-procedures.html"><a href="resampling-procedures.html#significance-testing-using-permutation-randomisation-tests"><i class="fa fa-check"></i><b>11.3</b> Significance testing using permutation (<em>randomisation</em>) tests</a><ul>
<li class="chapter" data-level="11.3.1" data-path="resampling-procedures.html"><a href="resampling-procedures.html#permutation-test-on-two-independent-samples"><i class="fa fa-check"></i><b>11.3.1</b> Permutation Test on Two Independent Samples</a></li>
<li class="chapter" data-level="11.3.2" data-path="resampling-procedures.html"><a href="resampling-procedures.html#p-values-from-permutation-tests"><i class="fa fa-check"></i><b>11.3.2</b> P-values from permutation tests</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="resampling-procedures.html"><a href="resampling-procedures.html#the-bootstrap"><i class="fa fa-check"></i><b>11.4</b> The bootstrap</a><ul>
<li class="chapter" data-level="11.4.1" data-path="resampling-procedures.html"><a href="resampling-procedures.html#example-constructing-bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>11.4.1</b> Example: constructing bootstrap confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="resampling-procedures.html"><a href="resampling-procedures.html#differences-between-permutation-test-and-bootstrap-test"><i class="fa fa-check"></i><b>11.5</b> Differences between permutation test and bootstrap test</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html"><i class="fa fa-check"></i><b>12</b> Multivariate Data Methods</a><ul>
<li class="chapter" data-level="12.1" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html#learning-objectives-11"><i class="fa fa-check"></i><b>12.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="12.2" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html#clustering"><i class="fa fa-check"></i><b>12.2</b> Clustering</a><ul>
<li class="chapter" data-level="12.2.1" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html#clustering-algorithms"><i class="fa fa-check"></i><b>12.2.1</b> Clustering algorithms</a></li>
<li class="chapter" data-level="12.2.2" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html#with-ants"><i class="fa fa-check"></i><b>12.2.2</b> With ants</a></li>
<li class="chapter" data-level="12.2.3" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html#k-means-using-the-palmerpenguins-data"><i class="fa fa-check"></i><b>12.2.3</b> k-means using the <code>palmerpenguins</code> data</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html#tldr-k-means-clustering"><i class="fa fa-check"></i><b>12.3</b> TL;DR k-means clustering</a></li>
<li class="chapter" data-level="12.4" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html#other-resources-optional-but-recommended-1"><i class="fa fa-check"></i><b>12.4</b> Other resources: optional but recommended</a><ul>
<li class="chapter" data-level="12.4.1" data-path="multivariate-data-methods.html"><a href="multivariate-data-methods.html#multidimensional-scaling-in-r-not-examinable"><i class="fa fa-check"></i><b>12.4.1</b> Multidimensional Scaling in <code>R</code> (<em>not examinable</em>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="dimension-reduction.html"><a href="dimension-reduction.html"><i class="fa fa-check"></i><b>13</b> Dimension reduction</a><ul>
<li class="chapter" data-level="13.1" data-path="dimension-reduction.html"><a href="dimension-reduction.html#learning-objectives-12"><i class="fa fa-check"></i><b>13.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="13.2" data-path="dimension-reduction.html"><a href="dimension-reduction.html#dimension-reduction-1"><i class="fa fa-check"></i><b>13.2</b> Dimension reduction</a></li>
<li class="chapter" data-level="13.3" data-path="dimension-reduction.html"><a href="dimension-reduction.html#pca-in-r"><i class="fa fa-check"></i><b>13.3</b> PCA in <code>R</code></a><ul>
<li class="chapter" data-level="13.3.1" data-path="dimension-reduction.html"><a href="dimension-reduction.html#using-the-palmerpenguins-data"><i class="fa fa-check"></i><b>13.3.1</b> Using the <code>palmerpenguins</code> data</a></li>
<li class="chapter" data-level="13.3.2" data-path="dimension-reduction.html"><a href="dimension-reduction.html#athletes"><i class="fa fa-check"></i><b>13.3.2</b> Athletes</a></li>
<li class="chapter" data-level="13.3.3" data-path="dimension-reduction.html"><a href="dimension-reduction.html#ants-from-previous-chapter"><i class="fa fa-check"></i><b>13.3.3</b> Ants (from previous chapter)</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="dimension-reduction.html"><a href="dimension-reduction.html#reality-check-reducing-noise..."><i class="fa fa-check"></i><b>13.4</b> Reality check: reducing noise...</a></li>
<li class="chapter" data-level="13.5" data-path="dimension-reduction.html"><a href="dimension-reduction.html#other-resources-optional-but-recommended-2"><i class="fa fa-check"></i><b>13.5</b> Other resources: optional but recommended</a><ul>
<li class="chapter" data-level="13.5.1" data-path="dimension-reduction.html"><a href="dimension-reduction.html#multidimensional-scaling-in-r"><i class="fa fa-check"></i><b>13.5.1</b> Multidimensional Scaling in <code>R</code></a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>bluebook</em> BIOSCI738</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multivariate-data-methods" class="section level1">
<h1><span class="header-section-number">12</span> Multivariate Data Methods</h1>
<div id="learning-objectives-11" class="section level2">
<h2><span class="header-section-number">12.1</span> Learning Objectives</h2>
<ul>
<li>Explain the aims and motivation behind cluster analysis and its relevance in biology</li>
<li>Write <code>R</code> code to carry out hierarchical and k-means cluster analysis</li>
<li>Interpret <code>R</code> output from hierarchical and k-means cluster analysis</li>
<li>Interpret and communicate, to both a statistical and non-statistical audience, clustering techniques, specifically,
<ul>
<li><em>Divisive methods</em>, nonparametric algorithms such as k-means</li>
<li><em>Agglomerative methods</em>, clustering cases and/or variables into a hierarchy of sets (i.e., hierarchical clustering)</li>
</ul></li>
</ul>
</div>
<div id="clustering" class="section level2">
<h2><span class="header-section-number">12.2</span> Clustering</h2>
<p>So, it's all about variation again! And the idea of minimizing it.</p>
<p><strong>Goals</strong></p>
<ul>
<li>See measures of (dis)similarity and distances that help us define clusters.</li>
<li>Uncover hidden or latent clustering by partitioning the data into tighter sets.</li>
<li><em>Divisive methods</em>: nonparametric algorithms such as k-means to split data into a small number of clusters.</li>
<li><em>Agglomerative methods</em>: clustering cases and/or variables into a hierarchy of sets - hierarchical clustering.</li>
<li>Study how to validate clusters through resampling-based bootstrap methods</li>
</ul>
<div id="clustering-algorithms" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Clustering algorithms</h3>
<ul>
<li><p>The distances are used to construct the clusters.</p>
<ul>
<li>Agglomerative methods, that build a hierarchical clustering tree</li>
<li>Partitioning methods that separate the data into subsets</li>
</ul></li>
</ul>
<p>Both types of methods require a choice to be made: the number k of clusters.</p>
<ul>
<li>Partitioning methods such as k-means this choice has to be made at the outset whereas for hierarchical clustering this can be deferred to the end of the analysis.</li>
</ul>
<div id="k-means" class="section level4">
<h4><span class="header-section-number">12.2.1.1</span> k-means</h4>
<p>K-means clustering involves defining clusters so that the overall variation within a cluster (known as total within-cluster variation) is minimized. How do we define this variation? Typically, using Euclidean distances; the total within-cluster variation, is in this case, is defined as the sum of squared distances Euclidean distances between observations and the corresponding cluster centroid.</p>
<p>In summary, this is the procedure</p>
<ul>
<li>The number of clusters (k) are specified</li>
<li>k objects from the dataset are selected at random and <em>set</em> as the initial cluster centers or means</li>
<li>Each observation is assigned to their closest centroid (<em>based on the Euclidean distance between the object and the centroid</em>)</li>
<li>For each of the k clusters the cluster centroid is then updated based on calculating the new mean values of all the data points in the cluster</li>
<li>Repeat the two previous steps until 1) the cluster assignments stop changing or 2) the maximum number of iterations is reached</li>
</ul>
</div>
<div id="hierarchical-clustering" class="section level4">
<h4><span class="header-section-number">12.2.1.2</span> Hierarchical clustering</h4>
<p>Hierarchical clustering is a bottom-up approach: + similar observations and subclasses are assembled iteratively</p>
<p>Linnaeus made nested clusters of organisms according to specific characteristics. The order of the labels does not matter within sibling pairs. + Horizontal distances are usually meaningless + Vertical distances can encode some information.</p>
<p>In summary, this is the procedure</p>
<ul>
<li>Start with a matrix of distances, (or similarities) between pairs of observations (cases)</li>
<li>Choice of distance measure key first step</li>
<li>Algorithm:
<ul>
<li>Initial n singleton clusters</li>
<li>Scan distance matrix for two closest individuals, group them together</li>
<li>Compute distance from cluster of size 2 to remaining n-1 singleton clusters</li>
</ul></li>
</ul>
<p><strong>Ways to calculate distances between the aggregates</strong></p>
<ul>
<li>Single Linkage (<em>nearest neighbour/minimal jump</em>): Computes the distance between clusters as the smallest distance between any two points in the two clusters</li>
</ul>
<div class="figure">
<img src="img/single_linkage.png" />

</div>
<ul>
<li>Complete Linkage (<em>maximum jump</em>): Calculates the maximum distance betweentwo points from each cluster</li>
</ul>
<div class="figure">
<img src="img/maximum_linkage.png" />

</div>
<ul>
<li><p>Average linkage: Computes the mean of distances between all pairs of observations</p></li>
<li><p>Ward's method: where the goal is to minimize the variance within clusters</p></li>
</ul>
<div class="figure">
<img src="img/wards_linkage.png" />

</div>
<table>
<thead>
<tr class="header">
<th>Method</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Single linkage</td>
<td>number of clusters</td>
<td>comblike trees.</td>
</tr>
<tr class="even">
<td>Complete linkage</td>
<td>compact clusters</td>
<td>one obs. can alter groups</td>
</tr>
<tr class="odd">
<td>Average linkage</td>
<td>similar size and variance</td>
<td>not robust</td>
</tr>
<tr class="even">
<td>Centroid</td>
<td>robust to outliers</td>
<td>smaller number of clusters</td>
</tr>
<tr class="odd">
<td>Ward</td>
<td>minimising an inertia</td>
<td>clusters small if high variability</td>
</tr>
</tbody>
</table>
</div>
<div id="identify-optimal-number-of-clusters" class="section level4">
<h4><span class="header-section-number">12.2.1.3</span> Identify optimal number of clusters</h4>
<p>Identifying the appropriate k is important because too many or too few clusters impedes viewing overall trends. Too many clusters can lead to over-fitting (which limits generalizations) while insufficient clusters limits insights into commonality of groups.</p>
<p>There are assorted methodologies to identify the appropriate <span class="math inline">\(k\)</span>. Tests range from blunt visual inspections to robust algorithms. The optimal number of clusters is ultimately a <strong>subjective decision</strong>.</p>
</div>
</div>
<div id="with-ants" class="section level3">
<h3><span class="header-section-number">12.2.2</span> With ants</h3>
<p>The data <code>pitfalls.csv</code> is available on CANVAS</p>
<p>Data were collected on the distribution of ant species at 30 sites across the Auckland region using pitfall traps.</p>
<ul>
<li><p>Twenty pitfall traps at each site were left open for ten days and the number of individuals captured counted</p></li>
<li><p>Data used here are standardised <span class="math inline">\(\text{log}(x + 1)\)</span> transformed for the four most abundant species:</p>
<ul>
<li><em>Nylanderia spp</em></li>
<li><em>Pheidole rugosula</em></li>
<li><em>Tetramorium grassii</em></li>
<li><em>Pachycondyla sp</em></li>
</ul></li>
</ul>
<p>At each location twenty pitfall traps were placed in each of four habitats (Forest, Grass, Urban, Scrub) and left for ten days. At the end of this sampling all individuals in the pitfall traps were identified and summed at each site (location x habitat). This sampling protocol was repeated for 3 months over summer 2011.</p>
<pre><code>## # A tibble: 30 x 8
##    Location Habitat Month Site    Nyl   Phe   Tet   Pac
##    &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 West     Forest      1 WF1       0     0     0   157
##  2 West     Grass       1 WG1       0     2     7    37
##  3 West     Urban       1 WU1       3     7     0     0
##  4 West     Forest      2 WF2       0     0     0    31
##  5 West     Grass       2 WG2       5     0    25     0
##  6 West     Forest      3 WF3       0     0     0    21
##  7 West     Grass       3 WG3       0     3     2     1
##  8 West     Urban       3 WU3       0     1     0     0
##  9 Central  Forest      1 CF1       0     0     0     1
## 10 Central  Grass       1 CG1       0     3    22     2
## # … with 20 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
ants &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;pitfalls.csv&quot;</span>)</code></pre></div>
<p><strong>Hierarchical clustering</strong></p>
<p>Data are species counts, so we will use Bray Curtis measure:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pitfall.dist &lt;-<span class="st"> </span>vegan<span class="op">::</span><span class="kw">vegdist</span>(ants[,<span class="dv">5</span><span class="op">:</span><span class="dv">8</span>], <span class="dt">method =</span> <span class="st">&quot;bray&quot;</span>, <span class="dt">binary =</span> <span class="ot">FALSE</span>)
factoextra<span class="op">::</span><span class="kw">fviz_dist</span>(pitfall.dist)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-96-1.png" width="672" /></p>
<p>Computing 4 dendrograms</p>
<ul>
<li>Single-linkage</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">single &lt;-<span class="st"> </span>ants[,<span class="dv">5</span><span class="op">:</span><span class="dv">8</span>] <span class="op">%&gt;%</span>
<span class="st">  </span>vegan<span class="op">::</span><span class="kw">vegdist</span>(., <span class="dt">method =</span> <span class="st">&quot;bray&quot;</span>, <span class="dt">binary =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;single&quot;</span>)
<span class="kw">plot</span>(single, <span class="dt">labels =</span> ants<span class="op">$</span>Site)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-97-1.png" width="672" /></p>
<ul>
<li>Maximum linkage</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">complete &lt;-<span class="st"> </span>ants[,<span class="dv">5</span><span class="op">:</span><span class="dv">8</span>] <span class="op">%&gt;%</span>
<span class="st">  </span>vegan<span class="op">::</span><span class="kw">vegdist</span>(., <span class="dt">method =</span> <span class="st">&quot;bray&quot;</span>, <span class="dt">binary =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;complete&quot;</span>)
<span class="kw">plot</span>(complete, <span class="dt">labels =</span> ants<span class="op">$</span>Site)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-98-1.png" width="672" /></p>
<ul>
<li>Average linkage (UPGMA)</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">average &lt;-<span class="st"> </span>ants[,<span class="dv">5</span><span class="op">:</span><span class="dv">8</span>] <span class="op">%&gt;%</span>
<span class="st">  </span>vegan<span class="op">::</span><span class="kw">vegdist</span>(., <span class="dt">method =</span> <span class="st">&quot;bray&quot;</span>, <span class="dt">binary =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;average&quot;</span>)
<span class="kw">plot</span>(average, <span class="dt">labels =</span> ants<span class="op">$</span>Site)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-99-1.png" width="672" /></p>
<ul>
<li>Ward’s</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ward &lt;-<span class="st"> </span>ants[,<span class="dv">5</span><span class="op">:</span><span class="dv">8</span>] <span class="op">%&gt;%</span>
<span class="st">  </span>vegan<span class="op">::</span><span class="kw">vegdist</span>(., <span class="dt">method =</span> <span class="st">&quot;bray&quot;</span>, <span class="dt">binary =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D&quot;</span>)
<span class="kw">plot</span>(ward, <span class="dt">labels =</span> ants<span class="op">$</span>Site)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-100-1.png" width="672" /></p>
<p><strong>WHAT ARE DENDROGRAMS GOOD FOR?</strong> Suggesting clusters for further study...</p>
<p>Using the function <code>cutree()</code> to split into clusters and plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ants<span class="op">$</span>clust4 &lt;-<span class="st"> </span><span class="kw">cutree</span>(ward, <span class="dt">k =</span> <span class="dv">4</span>)
<span class="kw">library</span>(ape)   ## install
pitfall.phylo &lt;-<span class="st"> </span><span class="kw">as.phylo</span>(ward)
pitfall.phylo<span class="op">$</span>tip.label &lt;-<span class="st"> </span>ants<span class="op">$</span>Site
## Set colours 
colours  &lt;-<span class="st">  </span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>,<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;green&quot;</span>,<span class="st">&quot;black&quot;</span>)
<span class="kw">plot</span>(pitfall.phylo, <span class="dt">cex =</span> <span class="fl">0.6</span>, <span class="dt">tip.color =</span> colours[ants<span class="op">$</span>clust4], <span class="dt">label.offset =</span> <span class="fl">0.05</span>) </code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-101-1.png" width="672" /></p>
</div>
<div id="k-means-using-the-palmerpenguins-data" class="section level3">
<h3><span class="header-section-number">12.2.3</span> k-means using the <code>palmerpenguins</code> data</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(palmerpenguins)
## getting rid of NAs
penguins_nafree &lt;-<span class="st"> </span>penguins <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop_na</span>()</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## introducing a new package GGally, please install
## using install.packages(&quot;GGally&quot;)
<span class="kw">library</span>(GGally)
penguins_nafree <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(species, <span class="kw">where</span>(is.numeric)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggpairs</span>(<span class="dt">columns =</span> <span class="kw">c</span>(<span class="st">&quot;flipper_length_mm&quot;</span>, <span class="st">&quot;body_mass_g&quot;</span>, 
                     <span class="st">&quot;bill_length_mm&quot;</span>, <span class="st">&quot;bill_depth_mm&quot;</span>)) </code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
<p>We see that a lot of these variables (e.g., <code>flipper_length_mm</code>, <code>body_mass_g</code>, and <code>bill_length_mm</code>) are relatively strongly (positively) related to one another. Could they actually be telling us the same information? Combined we could think of these three variables all telling us a little about <em>bigness</em> of penguin. Is there a way we could reduce these three variables, into say 1, to represent the <em>bigness</em> of a penguin. We may not need <em>all</em> the information (variation) captured by these variables, but could get away with fewer <em>new uncorrelated</em> variables that represent basically the same information (e.g., penguin <em>bigness</em>), thereby, <strong>reducing the dimensionality of the data</strong> (more on this later).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## create a data frame of what we&#39;re interested in
df &lt;-<span class="st"> </span>penguins_nafree <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="kw">where</span>(is.numeric), <span class="op">-</span>year)</code></pre></div>
<p>We use the <code>kmeans()</code> function.</p>
<p>The first argument of <code>kmeans()</code> should be the dataset you wish to cluster. Below we use data frame <code>df</code>, the penguin data discussed above. But how many clusters do we choose? Let's try 1 to 5... (i.e., using the <code>centers</code> argument). Setting <code>nstart = 25</code> means that R will try 25 different random starting assignments and then select the best results corresponding to the one with the lowest within cluster variation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## set the seed so we all start off in the same place
<span class="kw">set.seed</span>(<span class="dv">4321</span>)
## one cluster
k1 &lt;-<span class="st"> </span><span class="kw">kmeans</span>(df, <span class="dt">centers =</span> <span class="dv">1</span>, <span class="dt">nstart =</span> <span class="dv">25</span>)
## two clusters
k2 &lt;-<span class="st"> </span><span class="kw">kmeans</span>(df, <span class="dt">centers =</span> <span class="dv">2</span>, <span class="dt">nstart =</span> <span class="dv">25</span>)
## three clusters
k3 &lt;-<span class="st"> </span><span class="kw">kmeans</span>(df, <span class="dt">centers =</span> <span class="dv">3</span>, <span class="dt">nstart =</span> <span class="dv">25</span>)
## four clusters
k4 &lt;-<span class="st"> </span><span class="kw">kmeans</span>(df, <span class="dt">centers =</span> <span class="dv">4</span>, <span class="dt">nstart =</span> <span class="dv">25</span>)
## five clusters
k5 &lt;-<span class="st"> </span><span class="kw">kmeans</span>(df, <span class="dt">centers =</span> <span class="dv">5</span>, <span class="dt">nstart =</span> <span class="dv">25</span>)</code></pre></div>
<p>The <code>kmeans()</code> function returns a list of components:</p>
<ul>
<li><code>cluster</code>, integers indicating the cluster to which each observation is allocated</li>
<li><code>centers</code>, a matrix of cluster centers/means</li>
<li><code>totss</code>, the total sum of squares</li>
<li><code>withinss</code>, within-cluster sum of squares, one component per cluster</li>
<li><code>tot.withinss</code>, total within-cluster sum of squares</li>
<li><code>betweenss</code>, between-cluster sum of squares</li>
<li><code>size</code>, number of observations in each cluster</li>
</ul>
<div id="choosing-the-number-of-clusters" class="section level4">
<h4><span class="header-section-number">12.2.3.1</span> Choosing the number of clusters</h4>
<p>We have an idea there may be 3 clusters, perhaps, but how do we know this is the best fit? Remember it's a <strong>subjective choice</strong> and we'll be looking at a few pointers</p>
<p><strong>Visual inspection</strong> method</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(factoextra) ## a new packahe for kmeasn viz, please install
p1 &lt;-<span class="st"> </span><span class="kw">fviz_cluster</span>(k1, <span class="dt">data =</span> df)
p2 &lt;-<span class="st"> </span><span class="kw">fviz_cluster</span>(k2, <span class="dt">data =</span> df)
p3 &lt;-<span class="st"> </span><span class="kw">fviz_cluster</span>(k3, <span class="dt">data =</span> df)
p4 &lt;-<span class="st"> </span><span class="kw">fviz_cluster</span>(k4, <span class="dt">data =</span> df)
p5 &lt;-<span class="st"> </span><span class="kw">fviz_cluster</span>(k5, <span class="dt">data =</span> df)

## for arranging plots
<span class="kw">library</span>(patchwork) 
(p1<span class="op">|</span><span class="st"> </span>p2<span class="op">|</span><span class="st"> </span>p3)<span class="op">/</span><span class="st"> </span>(p4 <span class="op">|</span><span class="st"> </span>p5)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-106-1.png" width="672" /></p>
<p>Alternatively, you can use standard pairwise scatter plots to illustrate the clusters compared to the original variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">cluster =</span> k3<span class="op">$</span>cluster,
         <span class="dt">species =</span> penguins_nafree<span class="op">$</span>species) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(flipper_length_mm, bill_depth_mm, <span class="dt">color =</span> <span class="kw">factor</span>(cluster), <span class="dt">label =</span> species)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>()</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-107-1.png" width="672" /></p>
<p><strong>Elbow</strong> method</p>
<p>Optimal clusters are at the point in which the knee &quot;bends&quot; or in mathematical terms when the marginal total within sum of squares (<code>tot.withinss</code>) for an additional cluster begins to decrease at a linear rate</p>
<p>This is easier to see via a plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fviz_nbclust</span>(df, kmeans, <span class="dt">method =</span> <span class="st">&quot;wss&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Elbow method&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-108-1.png" width="672" /></p>
<p>There is a pretty obvious inflection (elbow) at 2 clusters, but maybe at 3 too. We can rule out an optimal number of clusters above 3 as there is then only a minimal marginal reduction in total within sum of squares. However, the model is ambiguous on whether 2 or 3 clusters is optimal...</p>
<p><strong>Silhouette</strong> method</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Silhouette method</span>
<span class="kw">fviz_nbclust</span>(df, kmeans, <span class="dt">method =</span> <span class="st">&quot;silhouette&quot;</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Silhouette method&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-109-1.png" width="672" /></p>
<p><strong>Gap</strong> method</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Gap statistic</span>
<span class="co"># recommended value: nboot = 500 for your analysis (it will take a while)</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>) ## remove this
<span class="kw">fviz_nbclust</span>(df, kmeans, <span class="dt">nstart =</span> <span class="dv">25</span>,  <span class="dt">method =</span> <span class="st">&quot;gap_stat&quot;</span>, <span class="dt">nboot =</span> <span class="dv">50</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Gap statistic method&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-110-1.png" width="672" /></p>
<p><strong>Basically it's up to you to collate all the suggestions and make and informed decision</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Trying all the cluster indecies AHHHHH
<span class="kw">library</span>(NbClust)
cluster_<span class="dv">30</span>_indexes &lt;-<span class="st"> </span><span class="kw">NbClust</span>(<span class="dt">data =</span> df, <span class="dt">distance =</span> <span class="st">&quot;euclidean&quot;</span>, <span class="dt">min.nc =</span> <span class="dv">2</span>, <span class="dt">max.nc =</span> <span class="dv">9</span>, <span class="dt">method =</span> <span class="st">&quot;complete&quot;</span>, <span class="dt">index =</span><span class="st">&quot;all&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-111-1.png" width="672" /></p>
<pre><code>## *** : The Hubert index is a graphical method of determining the number of clusters.
##                 In the plot of Hubert index, we seek a significant knee that corresponds to a 
##                 significant increase of the value of the measure i.e the significant peak in Hubert
##                 index second differences plot. 
## </code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-111-2.png" width="672" /></p>
<pre><code>## *** : The D index is a graphical method of determining the number of clusters. 
##                 In the plot of D index, we seek a significant knee (the significant peak in Dindex
##                 second differences plot) that corresponds to a significant increase of the value of
##                 the measure. 
##  
## ******************************************************************* 
## * Among all indices:                                                
## * 5 proposed 2 as the best number of clusters 
## * 6 proposed 3 as the best number of clusters 
## * 1 proposed 4 as the best number of clusters 
## * 4 proposed 5 as the best number of clusters 
## * 1 proposed 8 as the best number of clusters 
## * 3 proposed 9 as the best number of clusters 
## 
##                    ***** Conclusion *****                            
##  
## * According to the majority rule, the best number of clusters is  3 
##  
##  
## *******************************************************************</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fviz_nbclust</span>(cluster_<span class="dv">30</span>_indexes) <span class="op">+</span>
<span class="st">      </span><span class="kw">theme_minimal</span>() <span class="op">+</span>
<span class="st">      </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Frequency of Optimal Clusters using 30 indexes in NbClust Package&quot;</span>)</code></pre></div>
<pre><code>## Among all indices: 
## ===================
## * 2 proposed  0 as the best number of clusters
## * 1 proposed  1 as the best number of clusters
## * 5 proposed  2 as the best number of clusters
## * 6 proposed  3 as the best number of clusters
## * 1 proposed  4 as the best number of clusters
## * 4 proposed  5 as the best number of clusters
## * 1 proposed  8 as the best number of clusters
## * 3 proposed  9 as the best number of clusters
## * 3 proposed  NA&#39;s as the best number of clusters
## 
## Conclusion
## =========================
## * According to the majority rule, the best number of clusters is  3 .</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-111-3.png" width="672" /></p>
<p>Not obvious, basically still undecided between 2 and 3, but according to the absolute majority rule the &quot;best&quot; number is 3</p>
</div>
</div>
</div>
<div id="tldr-k-means-clustering" class="section level2">
<h2><span class="header-section-number">12.3</span> TL;DR k-means clustering</h2>
<p><strong><a href="https://github.com/allisonhorst/stats-illustrations">Artwork by @allison_horst</a></strong></p>
<p><img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_1.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_2.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_3.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_4.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_5.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_6.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_7.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_8.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_9.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_10.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_11.jpg" /> <img src="https://github.com/allisonhorst/stats-illustrations/raw/master/other-stats-artwork/kmeans_12.jpg" /></p>
</div>
<div id="other-resources-optional-but-recommended-1" class="section level2">
<h2><span class="header-section-number">12.4</span> Other resources: optional but recommended</h2>
<ul>
<li><p><a href="https://cmjt.github.io/statbiscuits/eigenfaces.html">Eigenfaces</a></p></li>
<li><p><a href="https://cmjt.github.io/statbiscuits/clusterducks.html">ClusterDucks</a></p></li>
<li><p><a href="https://little-book-of-r-for-multivariate-analysis.readthedocs.io/en/latest/index.html">Little book for Multivariate Analysis</a></p></li>
<li><p><a href="https://juba.github.io/explor/">'explor' is an R package to allow interactive exploration of multivariate analysis results</a></p></li>
<li><p><a href="https://towardsdatascience.com/the-mathematics-behind-principal-component-analysis-fff2d7f4b643">The Mathematics Behind Principal Component Analysis (6 min read)</a></p></li>
<li><p><a href="https://uc-r.github.io/kmeans_clustering">K-means cluster analysis</a></p></li>
</ul>
<div id="multidimensional-scaling-in-r-not-examinable" class="section level3">
<h3><span class="header-section-number">12.4.1</span> Multidimensional Scaling in <code>R</code> (<em>not examinable</em>)</h3>
<p>Multidimensional scaling (MDS) is actually the more general technique of dimension reduction. PCA is a special case of MDS!</p>
<p>To carry out MDS in <code>R</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggfortify)
## Plotting Multidimensional Scaling (for interest)
## stats::cmdscale performs Classical MDS
<span class="kw">data</span>(<span class="st">&quot;eurodist&quot;</span>) ## road distances (in km) between 21 cities in Europe.
<span class="kw">autoplot</span>(eurodist)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-112-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Plotting Classical (Metric) Multidimensional Scaling
<span class="kw">autoplot</span>(<span class="kw">cmdscale</span>(eurodist, <span class="dt">eig =</span> <span class="ot">TRUE</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-112-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">autoplot</span>(<span class="kw">cmdscale</span>(eurodist, <span class="dt">eig =</span> <span class="ot">TRUE</span>), <span class="dt">label =</span> <span class="ot">TRUE</span>, <span class="dt">shape =</span> <span class="ot">FALSE</span>,
         <span class="dt">label.size =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-112-3.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Plotting Non-metric Multidimensional Scaling
## MASS::isoMDS and MASS::sammon perform Non-metric MDS
<span class="kw">library</span>(MASS)
<span class="kw">autoplot</span>(<span class="kw">sammon</span>(eurodist))</code></pre></div>
<pre><code>## Initial stress        : 0.01705
## stress after  10 iters: 0.00951, magic = 0.500
## stress after  20 iters: 0.00941, magic = 0.500</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-112-4.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">autoplot</span>(<span class="kw">sammon</span>(eurodist), <span class="dt">shape =</span> <span class="ot">FALSE</span>, <span class="dt">label =</span> <span class="ot">TRUE</span>,<span class="dt">label.size =</span> <span class="dv">3</span>)</code></pre></div>
<pre><code>## Initial stress        : 0.01705
## stress after  10 iters: 0.00951, magic = 0.500
## stress after  20 iters: 0.00941, magic = 0.500</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-112-5.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Have a go at interpreting these plots based on the geography of the cities :-)</code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="resampling-procedures.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dimension-reduction.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
